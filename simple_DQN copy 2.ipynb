{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.gnn import MyModel, RGCN\n",
    "import torch\n",
    "from data.graph_loader import GraphLoader, load_highschool\n",
    "from torch_geometric.utils import to_networkx, to_undirected, degree\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "############################ DATA LOADING #########################\n",
    "device = torch.device(\"cuda:3\")\n",
    "# edge_index = load_highschool()\n",
    "# num_nodes = 70\n",
    "# edge_index = to_undirected(edge_index, num_nodes=num_nodes)\n",
    "# node_idx = torch.arange(num_nodes).to(device)\n",
    "# graph = Data(x=node_idx.cpu(), edge_index=edge_index)\n",
    "# nx_graph = to_networkx(graph)\n",
    "# node_degrees = degree(graph.edge_index[0], num_nodes=num_nodes)\n",
    "# random_walk_pe = torch.load(\"datasets/random_walk_pe_highschool_64.pt\").to(device)\n",
    "\n",
    "def create_clique(num_nodes):\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    x = torch.ones((num_nodes, 1))  # Node features\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Number of cliques and nodes per clique\n",
    "num_cliques = 5\n",
    "nodes_per_clique = 5\n",
    "\n",
    "# Create all cliques and combine them into a single graph\n",
    "all_nodes = []\n",
    "all_edges = []\n",
    "\n",
    "for k in range(num_cliques):\n",
    "    clique = create_clique(nodes_per_clique)\n",
    "    clique_edge_index = clique.edge_index + k * nodes_per_clique\n",
    "    all_nodes.append(clique.x)\n",
    "    all_edges.append(clique_edge_index)\n",
    "\n",
    "x = torch.cat(all_nodes, dim=0)\n",
    "edge_index = torch.cat(all_edges, dim=1)\n",
    "\n",
    "graph = Data(x=torch.eye(num_cliques*nodes_per_clique), edge_index=edge_index)\n",
    "nx_graph = to_networkx(graph)\n",
    "num_nodes = 25\n",
    "node_idx = torch.arange(num_nodes).to(device)\n",
    "\n",
    "############################ MODEL #########################\n",
    "hidden_dim = 25\n",
    "lr = 1e-4\n",
    "q_value = MyModel(num_nodes=num_nodes,\n",
    "    hidden_dim=hidden_dim).to(device)\n",
    "target_q_value = MyModel(num_nodes=num_nodes,\n",
    "    hidden_dim=hidden_dim).to(device)\n",
    "# q_value = RGCN(\n",
    "#     num_relations=2,\n",
    "#     input_dim=num_nodes,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     ).to(device)\n",
    "# target_q_value = RGCN(\n",
    "#     num_relations=2,\n",
    "#     input_dim=num_nodes,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     ).to(device)\n",
    "\n",
    "# initailize the embeddings and models\n",
    "# q_value.embeddings.weight.data = random_walk_pe\n",
    "target_q_value.load_state_dict(q_value.state_dict())\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(q_value.parameters(), lr=lr)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Dict, List, Tuple\n",
    "from utils.segment_tree import MinSegmentTree, SumSegmentTree\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.int_)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.full(size, False, dtype=bool)\n",
    "        \n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import networkx as nx\n",
    "\n",
    "class NodeImmunization(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        budget,\n",
    "        device,\n",
    "        graph,\n",
    "        oracle_calls = 100,\n",
    "        ):\n",
    "        self.budget = budget\n",
    "        self.oracle_calls = oracle_calls\n",
    "        self.device = device\n",
    "        self.nx_g = graph\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        reward, done = self._take_action(action)    \n",
    "        ob = self._build_ob()\n",
    "\n",
    "        return ob, reward, done\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        \n",
    "        \n",
    "        # compute reward and solution\n",
    "        previous_deleted_nodes = (self.x == 1).long()\n",
    "        reward = self._reward_compute(previous_deleted_nodes, action)\n",
    "        self.x[action] = 1\n",
    "        done = self._check_done()\n",
    "\n",
    "        return reward, done\n",
    "\n",
    "    def _reward_compute(self, node_index, action):\n",
    "        \n",
    "        # node_index = node_index.squeeze().cpu().numpy()\n",
    "        # node_index = node_index.nonzero()[0]\n",
    "        \n",
    "        mask = torch.where(node_index)[0].cpu().numpy()\n",
    "        mask[action] = 1\n",
    "        eigen_drop = compute_total_degree(self.nx_g, mask)\n",
    "        \n",
    "        new_reward = eigen_drop - self.old_reward\n",
    "        if new_reward< 0:\n",
    "            new_reward = 0\n",
    "\n",
    "        self.old_reward = eigen_drop\n",
    "\n",
    "        # new_reward = SV(self.nx_g, node_index, action)\n",
    "\n",
    "        \n",
    "            \n",
    "        return new_reward\n",
    "\n",
    "    def _check_done(self):\n",
    "        num_deleted = (self.x == 1).float()\n",
    "        return num_deleted.sum() == self.budget\n",
    "            \n",
    "    def _build_ob(self):\n",
    "        return self.x.float()\n",
    "        \n",
    "    def register(self, g, num_samples = 1):\n",
    "        self.g = g\n",
    "        self.num_samples = num_samples\n",
    "        self.g.to(self.device)\n",
    "        self.old_reward = 0\n",
    "        \n",
    "        num_nodes = self.g.x.shape[0]\n",
    "        self.x = torch.zeros(\n",
    "            num_nodes, \n",
    "            num_samples, \n",
    "            dtype = torch.long, \n",
    "            device = self.device\n",
    "            )\n",
    "        \n",
    "        # self.evaluation = ShieldValue(self.nx_g, self.device)\n",
    "        ob = self._build_ob()      \n",
    "        return ob\n",
    "    \n",
    "def compute_total_degree(graph, nodes):\n",
    "    unique_neighbors = set()\n",
    "    for node in nodes:\n",
    "        unique_neighbors.update(graph.neighbors(node))\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # Remove the nodes of interest from the unique neighbors set\n",
    "    unique_neighbors.update(nodes)\n",
    "    return len(unique_neighbors)\n",
    "\n",
    "class ShieldValue(torch.nn.Module):\n",
    "    def __init__(self, graph, device) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.G = graph\n",
    "        self.adj = nx.adjacency_matrix(self.G, dtype=float).tolil()\n",
    "        eigenval, eigenvec = sparse.linalg.eigsh(self.adj, k=1, which='LA')\n",
    "        self.eigenval = eigenval.item()\n",
    "        self.ori_eigenval = eigenval.item()\n",
    "\n",
    "        self.A = torch.from_numpy(self.adj.todense()).to(device)\n",
    "        self.eigenvec = torch.from_numpy(eigenvec).to(device).squeeze()\n",
    "\n",
    "\n",
    "    def forward(self, node_index):\n",
    "        eigenval = self.eigenval\n",
    "        eigenvec = self.eigenvec\n",
    "        adj = self.A\n",
    "\n",
    "        mask = (node_index == 1).squeeze()\n",
    "        term1 = 2*eigenval*(mask*(eigenvec**2)).sum()\n",
    "        masked_eigenvec = (eigenvec * mask).reshape(-1,1)\n",
    "        term2 = (adj * (masked_eigenvec @ masked_eigenvec.T)).sum()\n",
    "        eigendrop = term1 - term2\n",
    "        return eigendrop.item()\n",
    "    \n",
    "def SV(graph, node_index, action):\n",
    "    adj = nx.adjacency_matrix(graph, dtype=float).tolil()\n",
    "    mask = (node_index == 1).squeeze().cpu().numpy()\n",
    "    adj[mask, :] = 0\n",
    "    adj[:, mask] = 0\n",
    "    eigenval, eigenvec = sparse.linalg.eigsh(adj, k=1, which='LA')\n",
    "\n",
    "    device = node_index.device\n",
    "\n",
    "    eigenval = eigenval.item()\n",
    "    adj = torch.from_numpy(adj.todense()).to(device)\n",
    "    eigenvec = torch.from_numpy(eigenvec).to(device).squeeze()\n",
    "    mask = torch.zeros_like(node_index).squeeze()\n",
    "    mask[action] = 1\n",
    "\n",
    "    term1 = 2*eigenval*(mask*(eigenvec**2)).sum()\n",
    "    masked_eigenvec = (eigenvec * mask).reshape(-1,1)\n",
    "    term2 = (adj * (masked_eigenvec @ masked_eigenvec.T)).sum()\n",
    "    eigendrop = term1 - term2\n",
    "    return eigendrop.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1282319/292867754.py:89: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  G.done = torch.tensor([batch_data['done'][i]], dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9/2000 , Avg Loss: 342.7129, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.2036, STD: 0.5173\n",
      "Episode: 10/2000 , Avg Loss: 333.2426, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1947, STD: 0.5175\n",
      "Episode: 11/2000 , Avg Loss: 340.4869, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.1846, STD: 0.5178\n",
      "Episode: 12/2000 , Avg Loss: 337.2996, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1748, STD: 0.5181\n",
      "Episode: 13/2000 , Avg Loss: 327.6081, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.1647, STD: 0.5184\n",
      "Episode: 14/2000 , Avg Loss: 332.4951, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1529, STD: 0.5186\n",
      "Episode: 15/2000 , Avg Loss: 349.9607, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1447, STD: 0.5186\n",
      "Episode: 16/2000 , Avg Loss: 300.3804, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1350, STD: 0.5187\n",
      "Episode: 17/2000 , Avg Loss: 343.4356, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1255, STD: 0.5185\n",
      "Episode: 18/2000 , Avg Loss: 305.0954, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1161, STD: 0.5185\n",
      "Episode: 19/2000 , Avg Loss: 334.9624, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.1061, STD: 0.5185\n",
      "Episode: 20/2000 , Avg Loss: 331.6232, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.0964, STD: 0.5184\n",
      "Episode: 21/2000 , Avg Loss: 349.5855, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.0839, STD: 0.5186\n",
      "Episode: 22/2000 , Avg Loss: 330.8022, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.0728, STD: 0.5191\n",
      "Episode: 23/2000 , Avg Loss: 300.6044, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.0655, STD: 0.5195\n",
      "Episode: 24/2000 , Avg Loss: 329.4753, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.0563, STD: 0.5200\n",
      "Episode: 25/2000 , Avg Loss: 320.1060, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.0436, STD: 0.5203\n",
      "Episode: 26/2000 , Avg Loss: 309.9368, Eigenval: 4.0000, Neighbor: 15.0000, Mean: -0.0301, STD: 0.5208\n",
      "Episode: 27/2000 , Avg Loss: 326.6207, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.0202, STD: 0.5212\n",
      "Episode: 28/2000 , Avg Loss: 319.6366, Eigenval: 4.0000, Neighbor: 20.0000, Mean: -0.0089, STD: 0.5216\n",
      "Episode: 29/2000 , Avg Loss: 300.6723, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0017, STD: 0.5219\n",
      "Episode: 30/2000 , Avg Loss: 283.6558, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0172, STD: 0.5222\n",
      "Episode: 31/2000 , Avg Loss: 323.3054, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0265, STD: 0.5224\n",
      "Episode: 32/2000 , Avg Loss: 314.9613, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0371, STD: 0.5224\n",
      "Episode: 33/2000 , Avg Loss: 297.8471, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0505, STD: 0.5228\n",
      "Episode: 34/2000 , Avg Loss: 309.6061, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.0610, STD: 0.5233\n",
      "Episode: 35/2000 , Avg Loss: 307.3964, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.0721, STD: 0.5240\n",
      "Episode: 36/2000 , Avg Loss: 250.9704, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.0875, STD: 0.5248\n",
      "Episode: 37/2000 , Avg Loss: 332.9735, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.1045, STD: 0.5255\n",
      "Episode: 38/2000 , Avg Loss: 277.3716, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.1146, STD: 0.5264\n",
      "Episode: 39/2000 , Avg Loss: 285.8579, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.1317, STD: 0.5273\n",
      "Episode: 40/2000 , Avg Loss: 276.7577, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.1461, STD: 0.5281\n",
      "Episode: 41/2000 , Avg Loss: 358.1939, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.1603, STD: 0.5289\n",
      "Episode: 42/2000 , Avg Loss: 315.6194, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.1767, STD: 0.5297\n",
      "Episode: 43/2000 , Avg Loss: 319.4992, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.1892, STD: 0.5302\n",
      "Episode: 44/2000 , Avg Loss: 327.1704, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.2023, STD: 0.5307\n",
      "Episode: 45/2000 , Avg Loss: 338.7437, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 0.2248, STD: 0.5312\n",
      "Episode: 46/2000 , Avg Loss: 321.2638, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.2356, STD: 0.5318\n",
      "Episode: 47/2000 , Avg Loss: 270.0645, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.2560, STD: 0.5323\n",
      "Episode: 48/2000 , Avg Loss: 296.2318, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.2683, STD: 0.5327\n",
      "Episode: 49/2000 , Avg Loss: 324.2691, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 0.2853, STD: 0.5331\n",
      "Episode: 50/2000 , Avg Loss: 310.1539, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.3061, STD: 0.5336\n",
      "Episode: 51/2000 , Avg Loss: 291.0762, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.3202, STD: 0.5341\n",
      "Episode: 52/2000 , Avg Loss: 291.3585, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.3358, STD: 0.5347\n",
      "Episode: 53/2000 , Avg Loss: 322.9113, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.3614, STD: 0.5351\n",
      "Episode: 54/2000 , Avg Loss: 272.0996, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.3753, STD: 0.5354\n",
      "Episode: 55/2000 , Avg Loss: 292.5912, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 0.3923, STD: 0.5359\n",
      "Episode: 56/2000 , Avg Loss: 311.9925, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.4120, STD: 0.5363\n",
      "Episode: 57/2000 , Avg Loss: 278.7232, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 0.4302, STD: 0.5365\n",
      "Episode: 58/2000 , Avg Loss: 264.2279, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.4540, STD: 0.5369\n",
      "Episode: 59/2000 , Avg Loss: 301.4363, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.4714, STD: 0.5371\n",
      "Episode: 60/2000 , Avg Loss: 297.3092, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.4989, STD: 0.5374\n",
      "Episode: 61/2000 , Avg Loss: 334.9654, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 0.5147, STD: 0.5376\n",
      "Episode: 62/2000 , Avg Loss: 315.7382, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.5399, STD: 0.5380\n",
      "Episode: 63/2000 , Avg Loss: 305.8709, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.5545, STD: 0.5385\n",
      "Episode: 64/2000 , Avg Loss: 320.6018, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.5769, STD: 0.5389\n",
      "Episode: 65/2000 , Avg Loss: 285.9465, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.6029, STD: 0.5390\n",
      "Episode: 66/2000 , Avg Loss: 323.4945, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.6312, STD: 0.5392\n",
      "Episode: 67/2000 , Avg Loss: 341.9037, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.6538, STD: 0.5394\n",
      "Episode: 68/2000 , Avg Loss: 276.7582, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.6755, STD: 0.5397\n",
      "Episode: 69/2000 , Avg Loss: 291.8739, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.6989, STD: 0.5398\n",
      "Episode: 70/2000 , Avg Loss: 266.4446, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.7274, STD: 0.5399\n",
      "Episode: 71/2000 , Avg Loss: 276.2230, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.7475, STD: 0.5400\n",
      "Episode: 72/2000 , Avg Loss: 321.8657, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.7821, STD: 0.5401\n",
      "Episode: 73/2000 , Avg Loss: 255.2944, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.8086, STD: 0.5400\n",
      "Episode: 74/2000 , Avg Loss: 293.7646, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.8266, STD: 0.5400\n",
      "Episode: 75/2000 , Avg Loss: 303.6239, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 0.8560, STD: 0.5400\n",
      "Episode: 76/2000 , Avg Loss: 276.2973, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.8871, STD: 0.5400\n",
      "Episode: 77/2000 , Avg Loss: 283.7199, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 0.9182, STD: 0.5398\n",
      "Episode: 78/2000 , Avg Loss: 332.4231, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 0.9413, STD: 0.5398\n",
      "Episode: 79/2000 , Avg Loss: 274.9632, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 0.9800, STD: 0.5397\n",
      "Episode: 80/2000 , Avg Loss: 284.5158, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.0085, STD: 0.5398\n",
      "Episode: 81/2000 , Avg Loss: 313.7874, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.0357, STD: 0.5396\n",
      "Episode: 82/2000 , Avg Loss: 338.4034, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.0750, STD: 0.5396\n",
      "Episode: 83/2000 , Avg Loss: 316.9844, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.1003, STD: 0.5395\n",
      "Episode: 84/2000 , Avg Loss: 288.6845, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.1392, STD: 0.5396\n",
      "Episode: 85/2000 , Avg Loss: 275.3624, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.1774, STD: 0.5399\n",
      "Episode: 86/2000 , Avg Loss: 290.8605, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.2134, STD: 0.5404\n",
      "Episode: 87/2000 , Avg Loss: 302.4543, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 1.2220, STD: 0.5407\n",
      "Episode: 88/2000 , Avg Loss: 281.7945, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.2659, STD: 0.5409\n",
      "Episode: 89/2000 , Avg Loss: 281.2537, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.3181, STD: 0.5410\n",
      "Episode: 90/2000 , Avg Loss: 289.2807, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 1.3459, STD: 0.5411\n",
      "Episode: 91/2000 , Avg Loss: 256.4182, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.3768, STD: 0.5412\n",
      "Episode: 92/2000 , Avg Loss: 296.3392, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.4262, STD: 0.5415\n",
      "Episode: 93/2000 , Avg Loss: 287.3041, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.4686, STD: 0.5416\n",
      "Episode: 94/2000 , Avg Loss: 279.7497, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.5241, STD: 0.5416\n",
      "Episode: 95/2000 , Avg Loss: 266.8263, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.5319, STD: 0.5417\n",
      "Episode: 96/2000 , Avg Loss: 283.6830, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.5839, STD: 0.5418\n",
      "Episode: 97/2000 , Avg Loss: 254.3347, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.6338, STD: 0.5417\n",
      "Episode: 98/2000 , Avg Loss: 255.7215, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.6992, STD: 0.5418\n",
      "Episode: 99/2000 , Avg Loss: 246.6072, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.7104, STD: 0.5418\n",
      "Episode: 100/2000 , Avg Loss: 259.7726, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.7645, STD: 0.5420\n",
      "Episode: 101/2000 , Avg Loss: 334.0353, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 1.8208, STD: 0.5420\n",
      "Episode: 102/2000 , Avg Loss: 321.6377, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.8680, STD: 0.5421\n",
      "Episode: 103/2000 , Avg Loss: 283.4228, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 1.9110, STD: 0.5422\n",
      "Episode: 104/2000 , Avg Loss: 308.1254, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 1.9573, STD: 0.5422\n",
      "Episode: 105/2000 , Avg Loss: 306.5275, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.0195, STD: 0.5421\n",
      "Episode: 106/2000 , Avg Loss: 243.8315, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.0571, STD: 0.5422\n",
      "Episode: 107/2000 , Avg Loss: 261.1328, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.0958, STD: 0.5424\n",
      "Episode: 108/2000 , Avg Loss: 283.5311, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.1719, STD: 0.5425\n",
      "Episode: 109/2000 , Avg Loss: 281.5875, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.2197, STD: 0.5425\n",
      "Episode: 110/2000 , Avg Loss: 286.5659, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.2756, STD: 0.5427\n",
      "Episode: 111/2000 , Avg Loss: 260.0557, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.3359, STD: 0.5428\n",
      "Episode: 112/2000 , Avg Loss: 286.6659, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.3892, STD: 0.5429\n",
      "Episode: 113/2000 , Avg Loss: 243.6969, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.4210, STD: 0.5430\n",
      "Episode: 114/2000 , Avg Loss: 255.8234, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.4978, STD: 0.5429\n",
      "Episode: 115/2000 , Avg Loss: 240.8776, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.5479, STD: 0.5429\n",
      "Episode: 116/2000 , Avg Loss: 230.9503, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.5971, STD: 0.5429\n",
      "Episode: 117/2000 , Avg Loss: 223.1644, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.6591, STD: 0.5431\n",
      "Episode: 118/2000 , Avg Loss: 231.3370, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.7420, STD: 0.5433\n",
      "Episode: 119/2000 , Avg Loss: 215.4537, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.7746, STD: 0.5434\n",
      "Episode: 120/2000 , Avg Loss: 228.8108, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 2.8414, STD: 0.5435\n",
      "Episode: 121/2000 , Avg Loss: 306.7892, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.8856, STD: 0.5435\n",
      "Episode: 122/2000 , Avg Loss: 328.6325, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 2.9577, STD: 0.5434\n",
      "Episode: 123/2000 , Avg Loss: 318.1127, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 2.9967, STD: 0.5435\n",
      "Episode: 124/2000 , Avg Loss: 285.9744, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.1046, STD: 0.5437\n",
      "Episode: 125/2000 , Avg Loss: 281.9862, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.1340, STD: 0.5438\n",
      "Episode: 126/2000 , Avg Loss: 288.2252, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.1982, STD: 0.5440\n",
      "Episode: 127/2000 , Avg Loss: 268.0873, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.2814, STD: 0.5442\n",
      "Episode: 128/2000 , Avg Loss: 274.8814, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.3412, STD: 0.5443\n",
      "Episode: 129/2000 , Avg Loss: 292.6044, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.4183, STD: 0.5444\n",
      "Episode: 130/2000 , Avg Loss: 230.3858, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.4792, STD: 0.5444\n",
      "Episode: 131/2000 , Avg Loss: 235.0316, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.5569, STD: 0.5445\n",
      "Episode: 132/2000 , Avg Loss: 264.5324, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.6016, STD: 0.5444\n",
      "Episode: 133/2000 , Avg Loss: 265.1329, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 3.7120, STD: 0.5443\n",
      "Episode: 134/2000 , Avg Loss: 221.4169, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.7679, STD: 0.5442\n",
      "Episode: 135/2000 , Avg Loss: 245.5928, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.7998, STD: 0.5444\n",
      "Episode: 136/2000 , Avg Loss: 228.3988, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 3.8658, STD: 0.5447\n",
      "Episode: 137/2000 , Avg Loss: 235.7707, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 3.9554, STD: 0.5448\n",
      "Episode: 138/2000 , Avg Loss: 229.3361, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 4.0483, STD: 0.5450\n",
      "Episode: 139/2000 , Avg Loss: 215.0347, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 4.1291, STD: 0.5450\n",
      "Episode: 140/2000 , Avg Loss: 227.7011, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 4.2267, STD: 0.5449\n",
      "Episode: 141/2000 , Avg Loss: 321.0557, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 4.2820, STD: 0.5448\n",
      "Episode: 142/2000 , Avg Loss: 331.3316, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.3298, STD: 0.5448\n",
      "Episode: 143/2000 , Avg Loss: 317.5368, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.4324, STD: 0.5447\n",
      "Episode: 144/2000 , Avg Loss: 298.6066, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.4940, STD: 0.5447\n",
      "Episode: 145/2000 , Avg Loss: 268.0885, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.5742, STD: 0.5448\n",
      "Episode: 146/2000 , Avg Loss: 271.3445, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 4.6213, STD: 0.5449\n",
      "Episode: 147/2000 , Avg Loss: 297.1657, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.7573, STD: 0.5452\n",
      "Episode: 148/2000 , Avg Loss: 279.4530, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 4.8244, STD: 0.5454\n",
      "Episode: 149/2000 , Avg Loss: 239.0733, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 4.9112, STD: 0.5455\n",
      "Episode: 150/2000 , Avg Loss: 233.0675, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 5.0474, STD: 0.5455\n",
      "Episode: 151/2000 , Avg Loss: 261.6252, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.0616, STD: 0.5457\n",
      "Episode: 152/2000 , Avg Loss: 262.7956, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 5.1325, STD: 0.5459\n",
      "Episode: 153/2000 , Avg Loss: 257.7050, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.3010, STD: 0.5461\n",
      "Episode: 154/2000 , Avg Loss: 203.2703, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 5.3868, STD: 0.5463\n",
      "Episode: 155/2000 , Avg Loss: 240.7576, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.5038, STD: 0.5464\n",
      "Episode: 156/2000 , Avg Loss: 206.4183, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.5195, STD: 0.5463\n",
      "Episode: 157/2000 , Avg Loss: 256.8903, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.6314, STD: 0.5462\n",
      "Episode: 158/2000 , Avg Loss: 216.1672, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 5.7245, STD: 0.5462\n",
      "Episode: 159/2000 , Avg Loss: 202.5151, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 5.8251, STD: 0.5460\n",
      "Episode: 160/2000 , Avg Loss: 190.9527, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 5.9765, STD: 0.5456\n",
      "Episode: 161/2000 , Avg Loss: 340.8647, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 6.0506, STD: 0.5452\n",
      "Episode: 162/2000 , Avg Loss: 324.5503, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.1154, STD: 0.5450\n",
      "Episode: 163/2000 , Avg Loss: 326.9902, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.2071, STD: 0.5449\n",
      "Episode: 164/2000 , Avg Loss: 333.6997, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.3078, STD: 0.5448\n",
      "Episode: 165/2000 , Avg Loss: 351.1415, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 6.3937, STD: 0.5448\n",
      "Episode: 166/2000 , Avg Loss: 308.6598, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.5087, STD: 0.5449\n",
      "Episode: 167/2000 , Avg Loss: 267.1266, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.6273, STD: 0.5452\n",
      "Episode: 168/2000 , Avg Loss: 313.2775, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 6.7347, STD: 0.5454\n",
      "Episode: 169/2000 , Avg Loss: 275.1746, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 6.7617, STD: 0.5454\n",
      "Episode: 170/2000 , Avg Loss: 294.8867, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 6.8780, STD: 0.5455\n",
      "Episode: 171/2000 , Avg Loss: 281.2336, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 7.0538, STD: 0.5456\n",
      "Episode: 172/2000 , Avg Loss: 237.1447, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 7.1334, STD: 0.5456\n",
      "Episode: 173/2000 , Avg Loss: 237.3356, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 7.2258, STD: 0.5458\n",
      "Episode: 174/2000 , Avg Loss: 250.0390, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 7.3478, STD: 0.5460\n",
      "Episode: 175/2000 , Avg Loss: 271.8360, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 7.4550, STD: 0.5463\n",
      "Episode: 176/2000 , Avg Loss: 234.6320, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 7.6122, STD: 0.5466\n",
      "Episode: 177/2000 , Avg Loss: 257.7902, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 7.6247, STD: 0.5467\n",
      "Episode: 178/2000 , Avg Loss: 223.9029, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 7.8057, STD: 0.5462\n",
      "Episode: 179/2000 , Avg Loss: 244.3022, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 7.7976, STD: 0.5460\n",
      "Episode: 180/2000 , Avg Loss: 251.9505, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 7.9574, STD: 0.5458\n",
      "Episode: 181/2000 , Avg Loss: 394.6290, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 8.0436, STD: 0.5456\n",
      "Episode: 182/2000 , Avg Loss: 410.4144, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 8.1505, STD: 0.5454\n",
      "Episode: 183/2000 , Avg Loss: 398.1295, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 8.3355, STD: 0.5454\n",
      "Episode: 184/2000 , Avg Loss: 376.9052, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 8.3779, STD: 0.5455\n",
      "Episode: 185/2000 , Avg Loss: 334.6357, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 8.4420, STD: 0.5456\n",
      "Episode: 186/2000 , Avg Loss: 348.5295, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 8.5795, STD: 0.5458\n",
      "Episode: 187/2000 , Avg Loss: 347.2069, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 8.6063, STD: 0.5460\n",
      "Episode: 188/2000 , Avg Loss: 360.1363, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 8.8481, STD: 0.5464\n",
      "Episode: 189/2000 , Avg Loss: 361.9305, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.0169, STD: 0.5465\n",
      "Episode: 190/2000 , Avg Loss: 337.5778, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 9.0517, STD: 0.5465\n",
      "Episode: 191/2000 , Avg Loss: 354.8411, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.1928, STD: 0.5463\n",
      "Episode: 192/2000 , Avg Loss: 318.2186, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 9.2760, STD: 0.5461\n",
      "Episode: 193/2000 , Avg Loss: 364.4513, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 9.4097, STD: 0.5460\n",
      "Episode: 194/2000 , Avg Loss: 269.0096, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 9.5163, STD: 0.5459\n",
      "Episode: 195/2000 , Avg Loss: 333.7062, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.5411, STD: 0.5457\n",
      "Episode: 196/2000 , Avg Loss: 306.1392, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 9.7068, STD: 0.5455\n",
      "Episode: 197/2000 , Avg Loss: 268.5896, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.7473, STD: 0.5454\n",
      "Episode: 198/2000 , Avg Loss: 291.7778, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.8588, STD: 0.5456\n",
      "Episode: 199/2000 , Avg Loss: 332.0223, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 9.9765, STD: 0.5455\n",
      "Episode: 200/2000 , Avg Loss: 235.9422, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 10.0166, STD: 0.5453\n",
      "Episode: 201/2000 , Avg Loss: 490.1572, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 10.1992, STD: 0.5451\n",
      "Episode: 202/2000 , Avg Loss: 474.8547, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 10.2415, STD: 0.5451\n",
      "Episode: 203/2000 , Avg Loss: 548.6231, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 10.4975, STD: 0.5453\n",
      "Episode: 204/2000 , Avg Loss: 430.8355, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 10.5073, STD: 0.5454\n",
      "Episode: 205/2000 , Avg Loss: 509.0536, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 10.5674, STD: 0.5455\n",
      "Episode: 206/2000 , Avg Loss: 476.9329, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 10.7600, STD: 0.5453\n",
      "Episode: 207/2000 , Avg Loss: 494.1721, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 10.8269, STD: 0.5449\n",
      "Episode: 208/2000 , Avg Loss: 442.1318, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 11.0500, STD: 0.5443\n",
      "Episode: 209/2000 , Avg Loss: 422.7415, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 11.1260, STD: 0.5438\n",
      "Episode: 210/2000 , Avg Loss: 444.4628, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 11.2586, STD: 0.5434\n",
      "Episode: 211/2000 , Avg Loss: 448.5598, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.4706, STD: 0.5435\n",
      "Episode: 212/2000 , Avg Loss: 380.3301, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 11.4431, STD: 0.5436\n",
      "Episode: 213/2000 , Avg Loss: 410.3708, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.5469, STD: 0.5435\n",
      "Episode: 214/2000 , Avg Loss: 491.7267, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.6426, STD: 0.5432\n",
      "Episode: 215/2000 , Avg Loss: 464.2667, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.6272, STD: 0.5427\n",
      "Episode: 216/2000 , Avg Loss: 440.8917, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 11.7783, STD: 0.5422\n",
      "Episode: 217/2000 , Avg Loss: 486.5966, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 11.7666, STD: 0.5421\n",
      "Episode: 218/2000 , Avg Loss: 419.4680, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.6780, STD: 0.5422\n",
      "Episode: 219/2000 , Avg Loss: 428.3037, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 11.7733, STD: 0.5422\n",
      "Episode: 220/2000 , Avg Loss: 347.9045, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 11.9962, STD: 0.5421\n",
      "Episode: 221/2000 , Avg Loss: 606.8812, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.9807, STD: 0.5422\n",
      "Episode: 222/2000 , Avg Loss: 464.7816, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 11.9775, STD: 0.5422\n",
      "Episode: 223/2000 , Avg Loss: 559.7998, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.2128, STD: 0.5425\n",
      "Episode: 224/2000 , Avg Loss: 568.9361, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 12.3067, STD: 0.5429\n",
      "Episode: 225/2000 , Avg Loss: 636.8903, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.4017, STD: 0.5433\n",
      "Episode: 226/2000 , Avg Loss: 489.7357, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 12.5736, STD: 0.5433\n",
      "Episode: 227/2000 , Avg Loss: 548.1973, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.6379, STD: 0.5434\n",
      "Episode: 228/2000 , Avg Loss: 592.2908, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.7286, STD: 0.5432\n",
      "Episode: 229/2000 , Avg Loss: 606.3881, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.6729, STD: 0.5432\n",
      "Episode: 230/2000 , Avg Loss: 528.3799, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 12.8612, STD: 0.5433\n",
      "Episode: 231/2000 , Avg Loss: 493.7679, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 12.9705, STD: 0.5433\n",
      "Episode: 232/2000 , Avg Loss: 643.6655, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.1453, STD: 0.5432\n",
      "Episode: 233/2000 , Avg Loss: 554.0255, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.1044, STD: 0.5431\n",
      "Episode: 234/2000 , Avg Loss: 583.9288, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.2135, STD: 0.5428\n",
      "Episode: 235/2000 , Avg Loss: 560.8246, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.2289, STD: 0.5426\n",
      "Episode: 236/2000 , Avg Loss: 541.1259, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.3370, STD: 0.5423\n",
      "Episode: 237/2000 , Avg Loss: 603.5623, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.4133, STD: 0.5419\n",
      "Episode: 238/2000 , Avg Loss: 529.6791, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.1701, STD: 0.5415\n",
      "Episode: 239/2000 , Avg Loss: 635.4403, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.5645, STD: 0.5412\n",
      "Episode: 240/2000 , Avg Loss: 586.6854, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.3623, STD: 0.5409\n",
      "Episode: 241/2000 , Avg Loss: 594.7956, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 13.5010, STD: 0.5407\n",
      "Episode: 242/2000 , Avg Loss: 659.4148, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.6009, STD: 0.5403\n",
      "Episode: 243/2000 , Avg Loss: 775.4214, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.7234, STD: 0.5397\n",
      "Episode: 244/2000 , Avg Loss: 713.2572, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.6597, STD: 0.5393\n",
      "Episode: 245/2000 , Avg Loss: 750.5959, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.6787, STD: 0.5390\n",
      "Episode: 246/2000 , Avg Loss: 666.8695, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 13.9816, STD: 0.5387\n",
      "Episode: 247/2000 , Avg Loss: 616.6188, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.0834, STD: 0.5385\n",
      "Episode: 248/2000 , Avg Loss: 684.5332, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.0868, STD: 0.5387\n",
      "Episode: 249/2000 , Avg Loss: 564.0522, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.4110, STD: 0.5390\n",
      "Episode: 250/2000 , Avg Loss: 816.6718, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.3186, STD: 0.5392\n",
      "Episode: 251/2000 , Avg Loss: 683.4267, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.3094, STD: 0.5389\n",
      "Episode: 252/2000 , Avg Loss: 732.4492, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 14.2908, STD: 0.5386\n",
      "Episode: 253/2000 , Avg Loss: 686.3619, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.4077, STD: 0.5383\n",
      "Episode: 254/2000 , Avg Loss: 688.3945, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.4630, STD: 0.5380\n",
      "Episode: 255/2000 , Avg Loss: 558.3291, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.4254, STD: 0.5374\n",
      "Episode: 256/2000 , Avg Loss: 724.0840, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.4673, STD: 0.5373\n",
      "Episode: 257/2000 , Avg Loss: 953.5277, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.4873, STD: 0.5371\n",
      "Episode: 258/2000 , Avg Loss: 684.9070, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.5895, STD: 0.5364\n",
      "Episode: 259/2000 , Avg Loss: 566.6311, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.4987, STD: 0.5359\n",
      "Episode: 260/2000 , Avg Loss: 603.7952, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.4436, STD: 0.5355\n",
      "Episode: 261/2000 , Avg Loss: 707.8253, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.8115, STD: 0.5353\n",
      "Episode: 262/2000 , Avg Loss: 721.8852, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 14.8932, STD: 0.5357\n",
      "Episode: 263/2000 , Avg Loss: 697.4614, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.8012, STD: 0.5354\n",
      "Episode: 264/2000 , Avg Loss: 861.0765, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.8826, STD: 0.5350\n",
      "Episode: 265/2000 , Avg Loss: 820.2484, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.8688, STD: 0.5346\n",
      "Episode: 266/2000 , Avg Loss: 740.6337, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 14.9046, STD: 0.5346\n",
      "Episode: 267/2000 , Avg Loss: 669.0789, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 14.9991, STD: 0.5349\n",
      "Episode: 268/2000 , Avg Loss: 823.8551, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.0723, STD: 0.5349\n",
      "Episode: 269/2000 , Avg Loss: 569.9919, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.1785, STD: 0.5346\n",
      "Episode: 270/2000 , Avg Loss: 658.1287, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.2021, STD: 0.5344\n",
      "Episode: 271/2000 , Avg Loss: 812.7759, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.3120, STD: 0.5345\n",
      "Episode: 272/2000 , Avg Loss: 793.2508, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.4188, STD: 0.5344\n",
      "Episode: 273/2000 , Avg Loss: 688.4335, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.4418, STD: 0.5342\n",
      "Episode: 274/2000 , Avg Loss: 665.9581, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.2600, STD: 0.5339\n",
      "Episode: 275/2000 , Avg Loss: 778.5400, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.5033, STD: 0.5336\n",
      "Episode: 276/2000 , Avg Loss: 848.5130, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.4432, STD: 0.5334\n",
      "Episode: 277/2000 , Avg Loss: 824.7657, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.6365, STD: 0.5332\n",
      "Episode: 278/2000 , Avg Loss: 645.3482, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.5100, STD: 0.5329\n",
      "Episode: 279/2000 , Avg Loss: 737.7669, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.6536, STD: 0.5326\n",
      "Episode: 280/2000 , Avg Loss: 791.4701, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.3549, STD: 0.5324\n",
      "Episode: 281/2000 , Avg Loss: 943.9686, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.3658, STD: 0.5323\n",
      "Episode: 282/2000 , Avg Loss: 828.3558, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.3595, STD: 0.5324\n",
      "Episode: 283/2000 , Avg Loss: 892.3725, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.4882, STD: 0.5326\n",
      "Episode: 284/2000 , Avg Loss: 806.8861, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.5882, STD: 0.5328\n",
      "Episode: 285/2000 , Avg Loss: 878.9093, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.6634, STD: 0.5330\n",
      "Episode: 286/2000 , Avg Loss: 1032.9969, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.4396, STD: 0.5332\n",
      "Episode: 287/2000 , Avg Loss: 882.0500, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.6070, STD: 0.5334\n",
      "Episode: 288/2000 , Avg Loss: 743.9260, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.6443, STD: 0.5335\n",
      "Episode: 289/2000 , Avg Loss: 793.8938, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.7819, STD: 0.5338\n",
      "Episode: 290/2000 , Avg Loss: 944.2011, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.7286, STD: 0.5344\n",
      "Episode: 291/2000 , Avg Loss: 817.8611, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.7156, STD: 0.5347\n",
      "Episode: 292/2000 , Avg Loss: 843.9381, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.8100, STD: 0.5350\n",
      "Episode: 293/2000 , Avg Loss: 696.4995, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.9910, STD: 0.5351\n",
      "Episode: 294/2000 , Avg Loss: 765.3891, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.9122, STD: 0.5353\n",
      "Episode: 295/2000 , Avg Loss: 871.3703, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 15.9445, STD: 0.5355\n",
      "Episode: 296/2000 , Avg Loss: 829.5924, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.0438, STD: 0.5356\n",
      "Episode: 297/2000 , Avg Loss: 890.9135, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 16.0107, STD: 0.5356\n",
      "Episode: 298/2000 , Avg Loss: 917.6515, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 16.0339, STD: 0.5353\n",
      "Episode: 299/2000 , Avg Loss: 1017.3388, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.0584, STD: 0.5348\n",
      "Episode: 300/2000 , Avg Loss: 856.7035, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 15.8535, STD: 0.5344\n",
      "Episode: 301/2000 , Avg Loss: 887.7690, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 15.9718, STD: 0.5346\n",
      "Episode: 302/2000 , Avg Loss: 858.0540, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.0647, STD: 0.5349\n",
      "Episode: 303/2000 , Avg Loss: 872.7945, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.2434, STD: 0.5352\n",
      "Episode: 304/2000 , Avg Loss: 774.1205, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.2378, STD: 0.5356\n",
      "Episode: 305/2000 , Avg Loss: 880.1292, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.2610, STD: 0.5362\n",
      "Episode: 306/2000 , Avg Loss: 848.6086, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.3649, STD: 0.5367\n",
      "Episode: 307/2000 , Avg Loss: 863.7686, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.3283, STD: 0.5372\n",
      "Episode: 308/2000 , Avg Loss: 764.2416, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.5008, STD: 0.5382\n",
      "Episode: 309/2000 , Avg Loss: 829.1555, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.6886, STD: 0.5386\n",
      "Episode: 310/2000 , Avg Loss: 789.3404, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 16.6798, STD: 0.5391\n",
      "Episode: 311/2000 , Avg Loss: 892.2329, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.5873, STD: 0.5395\n",
      "Episode: 312/2000 , Avg Loss: 884.6146, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.7512, STD: 0.5397\n",
      "Episode: 313/2000 , Avg Loss: 660.1688, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.7023, STD: 0.5399\n",
      "Episode: 314/2000 , Avg Loss: 968.3273, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.7792, STD: 0.5401\n",
      "Episode: 315/2000 , Avg Loss: 843.0213, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.7993, STD: 0.5400\n",
      "Episode: 316/2000 , Avg Loss: 861.9522, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.9210, STD: 0.5399\n",
      "Episode: 317/2000 , Avg Loss: 1109.0006, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.8188, STD: 0.5398\n",
      "Episode: 318/2000 , Avg Loss: 949.6814, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.7566, STD: 0.5400\n",
      "Episode: 319/2000 , Avg Loss: 766.0668, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.8071, STD: 0.5404\n",
      "Episode: 320/2000 , Avg Loss: 792.8755, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 16.8490, STD: 0.5404\n",
      "Episode: 321/2000 , Avg Loss: 1038.2837, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.7852, STD: 0.5403\n",
      "Episode: 322/2000 , Avg Loss: 905.9547, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.7064, STD: 0.5405\n",
      "Episode: 323/2000 , Avg Loss: 869.4638, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 16.9029, STD: 0.5406\n",
      "Episode: 324/2000 , Avg Loss: 1155.3755, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 16.8662, STD: 0.5407\n",
      "Episode: 325/2000 , Avg Loss: 816.4772, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.0758, STD: 0.5407\n",
      "Episode: 326/2000 , Avg Loss: 901.2529, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.0105, STD: 0.5408\n",
      "Episode: 327/2000 , Avg Loss: 929.9037, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 17.1528, STD: 0.5407\n",
      "Episode: 328/2000 , Avg Loss: 936.4480, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.1152, STD: 0.5407\n",
      "Episode: 329/2000 , Avg Loss: 1153.7072, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.1574, STD: 0.5408\n",
      "Episode: 330/2000 , Avg Loss: 948.3490, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.2750, STD: 0.5410\n",
      "Episode: 331/2000 , Avg Loss: 773.3861, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 17.3558, STD: 0.5410\n",
      "Episode: 332/2000 , Avg Loss: 944.4728, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.3793, STD: 0.5407\n",
      "Episode: 333/2000 , Avg Loss: 1038.1545, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.3206, STD: 0.5407\n",
      "Episode: 334/2000 , Avg Loss: 800.6606, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.2820, STD: 0.5409\n",
      "Episode: 335/2000 , Avg Loss: 851.4559, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.1935, STD: 0.5413\n",
      "Episode: 336/2000 , Avg Loss: 1083.1594, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.1472, STD: 0.5416\n",
      "Episode: 337/2000 , Avg Loss: 1005.8230, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.2053, STD: 0.5417\n",
      "Episode: 338/2000 , Avg Loss: 941.1323, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.3962, STD: 0.5418\n",
      "Episode: 339/2000 , Avg Loss: 1192.6376, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.4113, STD: 0.5417\n",
      "Episode: 340/2000 , Avg Loss: 973.1561, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.3464, STD: 0.5415\n",
      "Episode: 341/2000 , Avg Loss: 1058.2584, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.3436, STD: 0.5415\n",
      "Episode: 342/2000 , Avg Loss: 985.0374, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.0764, STD: 0.5416\n",
      "Episode: 343/2000 , Avg Loss: 872.0205, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.2024, STD: 0.5421\n",
      "Episode: 344/2000 , Avg Loss: 821.0984, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.2867, STD: 0.5424\n",
      "Episode: 345/2000 , Avg Loss: 798.9033, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.3001, STD: 0.5429\n",
      "Episode: 346/2000 , Avg Loss: 975.8546, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.6024, STD: 0.5432\n",
      "Episode: 347/2000 , Avg Loss: 1171.4045, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.6151, STD: 0.5436\n",
      "Episode: 348/2000 , Avg Loss: 1032.1076, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.6218, STD: 0.5438\n",
      "Episode: 349/2000 , Avg Loss: 1030.9369, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.5908, STD: 0.5443\n",
      "Episode: 350/2000 , Avg Loss: 975.7782, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.6578, STD: 0.5448\n",
      "Episode: 351/2000 , Avg Loss: 867.0227, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.5596, STD: 0.5453\n",
      "Episode: 352/2000 , Avg Loss: 959.3709, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.6098, STD: 0.5456\n",
      "Episode: 353/2000 , Avg Loss: 871.4413, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.6399, STD: 0.5457\n",
      "Episode: 354/2000 , Avg Loss: 859.0814, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.5909, STD: 0.5457\n",
      "Episode: 355/2000 , Avg Loss: 695.8341, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 17.5608, STD: 0.5458\n",
      "Episode: 356/2000 , Avg Loss: 905.0356, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 17.9316, STD: 0.5457\n",
      "Episode: 357/2000 , Avg Loss: 905.2137, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.8974, STD: 0.5456\n",
      "Episode: 358/2000 , Avg Loss: 1041.0105, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.8257, STD: 0.5455\n",
      "Episode: 359/2000 , Avg Loss: 1075.6133, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 17.9797, STD: 0.5458\n",
      "Episode: 360/2000 , Avg Loss: 960.2731, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.8727, STD: 0.5462\n",
      "Episode: 361/2000 , Avg Loss: 1255.9269, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.7759, STD: 0.5468\n",
      "Episode: 362/2000 , Avg Loss: 1115.9144, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 17.8023, STD: 0.5473\n",
      "Episode: 363/2000 , Avg Loss: 1192.3067, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.0448, STD: 0.5474\n",
      "Episode: 364/2000 , Avg Loss: 807.0543, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.9307, STD: 0.5475\n",
      "Episode: 365/2000 , Avg Loss: 1162.0176, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.7985, STD: 0.5475\n",
      "Episode: 366/2000 , Avg Loss: 1167.6260, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 17.8045, STD: 0.5474\n",
      "Episode: 367/2000 , Avg Loss: 1190.1583, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1775, STD: 0.5473\n",
      "Episode: 368/2000 , Avg Loss: 1136.6179, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1694, STD: 0.5471\n",
      "Episode: 369/2000 , Avg Loss: 1120.0994, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.0168, STD: 0.5470\n",
      "Episode: 370/2000 , Avg Loss: 1028.4887, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.9047, STD: 0.5468\n",
      "Episode: 371/2000 , Avg Loss: 962.9468, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 17.9326, STD: 0.5464\n",
      "Episode: 372/2000 , Avg Loss: 1058.0563, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 17.9362, STD: 0.5462\n",
      "Episode: 373/2000 , Avg Loss: 858.5737, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 17.9232, STD: 0.5465\n",
      "Episode: 374/2000 , Avg Loss: 1145.4216, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1777, STD: 0.5467\n",
      "Episode: 375/2000 , Avg Loss: 1037.8897, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.2490, STD: 0.5469\n",
      "Episode: 376/2000 , Avg Loss: 1044.3209, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.3055, STD: 0.5469\n",
      "Episode: 377/2000 , Avg Loss: 979.7246, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.2314, STD: 0.5469\n",
      "Episode: 378/2000 , Avg Loss: 1001.7893, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.4856, STD: 0.5471\n",
      "Episode: 379/2000 , Avg Loss: 1118.9335, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.5082, STD: 0.5470\n",
      "Episode: 380/2000 , Avg Loss: 940.6346, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.3246, STD: 0.5469\n",
      "Episode: 381/2000 , Avg Loss: 1373.6749, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.3181, STD: 0.5467\n",
      "Episode: 382/2000 , Avg Loss: 1235.3932, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.4502, STD: 0.5464\n",
      "Episode: 383/2000 , Avg Loss: 1080.9688, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.2470, STD: 0.5463\n",
      "Episode: 384/2000 , Avg Loss: 1327.5771, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 18.2344, STD: 0.5465\n",
      "Episode: 385/2000 , Avg Loss: 1325.0248, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1681, STD: 0.5467\n",
      "Episode: 386/2000 , Avg Loss: 1433.9159, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1234, STD: 0.5470\n",
      "Episode: 387/2000 , Avg Loss: 1081.7311, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.3743, STD: 0.5470\n",
      "Episode: 388/2000 , Avg Loss: 1115.1216, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1102, STD: 0.5470\n",
      "Episode: 389/2000 , Avg Loss: 833.7341, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.1661, STD: 0.5471\n",
      "Episode: 390/2000 , Avg Loss: 1147.3860, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.1134, STD: 0.5476\n",
      "Episode: 391/2000 , Avg Loss: 987.8787, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.4433, STD: 0.5482\n",
      "Episode: 392/2000 , Avg Loss: 969.6124, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.4793, STD: 0.5481\n",
      "Episode: 393/2000 , Avg Loss: 1114.5407, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.5798, STD: 0.5481\n",
      "Episode: 394/2000 , Avg Loss: 1101.0446, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.7532, STD: 0.5481\n",
      "Episode: 395/2000 , Avg Loss: 1098.1349, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.5625, STD: 0.5482\n",
      "Episode: 396/2000 , Avg Loss: 1012.7851, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.7602, STD: 0.5486\n",
      "Episode: 397/2000 , Avg Loss: 1133.1545, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.7312, STD: 0.5488\n",
      "Episode: 398/2000 , Avg Loss: 1271.8124, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.6482, STD: 0.5493\n",
      "Episode: 399/2000 , Avg Loss: 1051.9755, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.7601, STD: 0.5495\n",
      "Episode: 400/2000 , Avg Loss: 898.4476, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.8089, STD: 0.5496\n",
      "Episode: 401/2000 , Avg Loss: 1144.5015, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.9758, STD: 0.5495\n",
      "Episode: 402/2000 , Avg Loss: 1155.9150, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.0388, STD: 0.5498\n",
      "Episode: 403/2000 , Avg Loss: 1136.7407, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1333, STD: 0.5501\n",
      "Episode: 404/2000 , Avg Loss: 1155.6654, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.9072, STD: 0.5504\n",
      "Episode: 405/2000 , Avg Loss: 995.5602, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9184, STD: 0.5504\n",
      "Episode: 406/2000 , Avg Loss: 1098.0528, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9199, STD: 0.5501\n",
      "Episode: 407/2000 , Avg Loss: 1365.4751, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.1150, STD: 0.5498\n",
      "Episode: 408/2000 , Avg Loss: 1386.7217, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.9988, STD: 0.5498\n",
      "Episode: 409/2000 , Avg Loss: 1085.7913, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.8972, STD: 0.5498\n",
      "Episode: 410/2000 , Avg Loss: 1212.2324, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9268, STD: 0.5502\n",
      "Episode: 411/2000 , Avg Loss: 1102.6451, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9203, STD: 0.5503\n",
      "Episode: 412/2000 , Avg Loss: 1144.8020, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.1718, STD: 0.5503\n",
      "Episode: 413/2000 , Avg Loss: 1209.3079, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9045, STD: 0.5500\n",
      "Episode: 414/2000 , Avg Loss: 1133.2109, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0148, STD: 0.5501\n",
      "Episode: 415/2000 , Avg Loss: 1053.1095, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2328, STD: 0.5510\n",
      "Episode: 416/2000 , Avg Loss: 1524.1670, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.8456, STD: 0.5517\n",
      "Episode: 417/2000 , Avg Loss: 1180.0117, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 18.8072, STD: 0.5520\n",
      "Episode: 418/2000 , Avg Loss: 1193.7110, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9074, STD: 0.5520\n",
      "Episode: 419/2000 , Avg Loss: 986.1268, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.7713, STD: 0.5521\n",
      "Episode: 420/2000 , Avg Loss: 1105.5597, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0086, STD: 0.5525\n",
      "Episode: 421/2000 , Avg Loss: 1253.2038, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1139, STD: 0.5528\n",
      "Episode: 422/2000 , Avg Loss: 1198.7651, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.9528, STD: 0.5532\n",
      "Episode: 423/2000 , Avg Loss: 1187.1549, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9836, STD: 0.5534\n",
      "Episode: 424/2000 , Avg Loss: 1032.3310, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9435, STD: 0.5537\n",
      "Episode: 425/2000 , Avg Loss: 1213.3367, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.1303, STD: 0.5540\n",
      "Episode: 426/2000 , Avg Loss: 1168.5857, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1666, STD: 0.5544\n",
      "Episode: 427/2000 , Avg Loss: 1329.6517, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9991, STD: 0.5549\n",
      "Episode: 428/2000 , Avg Loss: 1236.0424, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.0197, STD: 0.5553\n",
      "Episode: 429/2000 , Avg Loss: 1240.6706, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 18.9941, STD: 0.5559\n",
      "Episode: 430/2000 , Avg Loss: 740.9083, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 18.9991, STD: 0.5571\n",
      "Episode: 431/2000 , Avg Loss: 1080.4558, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1786, STD: 0.5581\n",
      "Episode: 432/2000 , Avg Loss: 968.6190, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1087, STD: 0.5589\n",
      "Episode: 433/2000 , Avg Loss: 1271.8851, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3806, STD: 0.5591\n",
      "Episode: 434/2000 , Avg Loss: 1417.0931, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3096, STD: 0.5593\n",
      "Episode: 435/2000 , Avg Loss: 1377.3467, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3672, STD: 0.5594\n",
      "Episode: 436/2000 , Avg Loss: 1432.2529, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4196, STD: 0.5595\n",
      "Episode: 437/2000 , Avg Loss: 1126.2790, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1464, STD: 0.5595\n",
      "Episode: 438/2000 , Avg Loss: 1074.2087, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0213, STD: 0.5599\n",
      "Episode: 439/2000 , Avg Loss: 1191.8924, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.0178, STD: 0.5602\n",
      "Episode: 440/2000 , Avg Loss: 992.3073, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.0083, STD: 0.5603\n",
      "Episode: 441/2000 , Avg Loss: 1268.7923, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1978, STD: 0.5604\n",
      "Episode: 442/2000 , Avg Loss: 1180.9115, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0327, STD: 0.5603\n",
      "Episode: 443/2000 , Avg Loss: 1148.8945, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1736, STD: 0.5603\n",
      "Episode: 444/2000 , Avg Loss: 909.9722, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3272, STD: 0.5602\n",
      "Episode: 445/2000 , Avg Loss: 1274.0390, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2502, STD: 0.5601\n",
      "Episode: 446/2000 , Avg Loss: 1344.2871, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.2535, STD: 0.5597\n",
      "Episode: 447/2000 , Avg Loss: 1212.3073, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4257, STD: 0.5596\n",
      "Episode: 448/2000 , Avg Loss: 1110.3049, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.2264, STD: 0.5592\n",
      "Episode: 449/2000 , Avg Loss: 1083.0933, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3136, STD: 0.5587\n",
      "Episode: 450/2000 , Avg Loss: 999.7429, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3581, STD: 0.5587\n",
      "Episode: 451/2000 , Avg Loss: 1271.3269, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3115, STD: 0.5590\n",
      "Episode: 452/2000 , Avg Loss: 1416.8090, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2507, STD: 0.5594\n",
      "Episode: 453/2000 , Avg Loss: 1220.3426, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4427, STD: 0.5595\n",
      "Episode: 454/2000 , Avg Loss: 1053.6546, Eigenval: 4.0000, Neighbor: 10.0000, Mean: 19.2309, STD: 0.5597\n",
      "Episode: 455/2000 , Avg Loss: 886.5345, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2131, STD: 0.5601\n",
      "Episode: 456/2000 , Avg Loss: 1253.9072, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.3623, STD: 0.5605\n",
      "Episode: 457/2000 , Avg Loss: 1354.0680, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5559, STD: 0.5607\n",
      "Episode: 458/2000 , Avg Loss: 1119.3540, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4818, STD: 0.5607\n",
      "Episode: 459/2000 , Avg Loss: 1215.3163, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2958, STD: 0.5607\n",
      "Episode: 460/2000 , Avg Loss: 1274.6640, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3089, STD: 0.5608\n",
      "Episode: 461/2000 , Avg Loss: 1430.4549, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.1907, STD: 0.5610\n",
      "Episode: 462/2000 , Avg Loss: 1146.8141, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 18.9402, STD: 0.5608\n",
      "Episode: 463/2000 , Avg Loss: 1107.7985, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0305, STD: 0.5607\n",
      "Episode: 464/2000 , Avg Loss: 1102.9663, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1315, STD: 0.5606\n",
      "Episode: 465/2000 , Avg Loss: 1203.9663, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.1103, STD: 0.5605\n",
      "Episode: 466/2000 , Avg Loss: 1196.1095, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2108, STD: 0.5603\n",
      "Episode: 467/2000 , Avg Loss: 1240.0267, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.0594, STD: 0.5595\n",
      "Episode: 468/2000 , Avg Loss: 1127.3042, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0710, STD: 0.5590\n",
      "Episode: 469/2000 , Avg Loss: 1133.5960, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.0105, STD: 0.5589\n",
      "Episode: 470/2000 , Avg Loss: 1075.2438, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2668, STD: 0.5593\n",
      "Episode: 471/2000 , Avg Loss: 1188.4543, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2757, STD: 0.5596\n",
      "Episode: 472/2000 , Avg Loss: 1203.1272, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.2318, STD: 0.5599\n",
      "Episode: 473/2000 , Avg Loss: 1011.1223, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.1226, STD: 0.5603\n",
      "Episode: 474/2000 , Avg Loss: 1092.6991, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4771, STD: 0.5608\n",
      "Episode: 475/2000 , Avg Loss: 1305.9435, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2458, STD: 0.5611\n",
      "Episode: 476/2000 , Avg Loss: 1124.8310, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2660, STD: 0.5615\n",
      "Episode: 477/2000 , Avg Loss: 1305.3755, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4311, STD: 0.5619\n",
      "Episode: 478/2000 , Avg Loss: 1152.5509, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2986, STD: 0.5621\n",
      "Episode: 479/2000 , Avg Loss: 1017.9940, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3369, STD: 0.5627\n",
      "Episode: 480/2000 , Avg Loss: 1273.5354, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3180, STD: 0.5633\n",
      "Episode: 481/2000 , Avg Loss: 1407.7508, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2320, STD: 0.5636\n",
      "Episode: 482/2000 , Avg Loss: 1106.0443, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3886, STD: 0.5642\n",
      "Episode: 483/2000 , Avg Loss: 1146.5667, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5684, STD: 0.5645\n",
      "Episode: 484/2000 , Avg Loss: 1221.1658, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5357, STD: 0.5646\n",
      "Episode: 485/2000 , Avg Loss: 1424.1112, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5382, STD: 0.5645\n",
      "Episode: 486/2000 , Avg Loss: 1303.4490, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4188, STD: 0.5650\n",
      "Episode: 487/2000 , Avg Loss: 902.6938, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3560, STD: 0.5654\n",
      "Episode: 488/2000 , Avg Loss: 1234.2309, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4907, STD: 0.5659\n",
      "Episode: 489/2000 , Avg Loss: 1367.2498, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5314, STD: 0.5663\n",
      "Episode: 490/2000 , Avg Loss: 1200.0736, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3415, STD: 0.5668\n",
      "Episode: 491/2000 , Avg Loss: 1240.3080, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4998, STD: 0.5671\n",
      "Episode: 492/2000 , Avg Loss: 1147.9411, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4067, STD: 0.5670\n",
      "Episode: 493/2000 , Avg Loss: 1057.1117, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5181, STD: 0.5667\n",
      "Episode: 494/2000 , Avg Loss: 1314.1494, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5695, STD: 0.5667\n",
      "Episode: 495/2000 , Avg Loss: 1314.3735, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4658, STD: 0.5670\n",
      "Episode: 496/2000 , Avg Loss: 1017.0697, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3218, STD: 0.5673\n",
      "Episode: 497/2000 , Avg Loss: 970.6586, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3365, STD: 0.5674\n",
      "Episode: 498/2000 , Avg Loss: 1225.5438, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4186, STD: 0.5678\n",
      "Episode: 499/2000 , Avg Loss: 1303.1786, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3359, STD: 0.5681\n",
      "Episode: 500/2000 , Avg Loss: 1176.8009, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3833, STD: 0.5684\n",
      "Episode: 501/2000 , Avg Loss: 1020.0151, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4335, STD: 0.5684\n",
      "Episode: 502/2000 , Avg Loss: 1362.9777, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4592, STD: 0.5686\n",
      "Episode: 503/2000 , Avg Loss: 1267.4104, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3766, STD: 0.5687\n",
      "Episode: 504/2000 , Avg Loss: 1128.2308, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4230, STD: 0.5687\n",
      "Episode: 505/2000 , Avg Loss: 1259.3796, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5221, STD: 0.5688\n",
      "Episode: 506/2000 , Avg Loss: 1574.9020, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7723, STD: 0.5686\n",
      "Episode: 507/2000 , Avg Loss: 1213.3893, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5398, STD: 0.5684\n",
      "Episode: 508/2000 , Avg Loss: 1545.3741, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4716, STD: 0.5684\n",
      "Episode: 509/2000 , Avg Loss: 1051.9789, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4674, STD: 0.5686\n",
      "Episode: 510/2000 , Avg Loss: 1232.1802, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5174, STD: 0.5687\n",
      "Episode: 511/2000 , Avg Loss: 1321.8090, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5803, STD: 0.5686\n",
      "Episode: 512/2000 , Avg Loss: 1085.7193, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3903, STD: 0.5689\n",
      "Episode: 513/2000 , Avg Loss: 1083.4914, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5041, STD: 0.5697\n",
      "Episode: 514/2000 , Avg Loss: 1125.2540, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5154, STD: 0.5703\n",
      "Episode: 515/2000 , Avg Loss: 1157.4628, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5182, STD: 0.5710\n",
      "Episode: 516/2000 , Avg Loss: 1096.3409, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5748, STD: 0.5716\n",
      "Episode: 517/2000 , Avg Loss: 1014.8765, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8092, STD: 0.5722\n",
      "Episode: 518/2000 , Avg Loss: 1006.7602, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6229, STD: 0.5726\n",
      "Episode: 519/2000 , Avg Loss: 1269.4406, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8185, STD: 0.5728\n",
      "Episode: 520/2000 , Avg Loss: 1391.4771, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9323, STD: 0.5729\n",
      "Episode: 521/2000 , Avg Loss: 1386.1630, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7917, STD: 0.5729\n",
      "Episode: 522/2000 , Avg Loss: 1646.2651, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4035, STD: 0.5729\n",
      "Episode: 523/2000 , Avg Loss: 1225.2765, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3934, STD: 0.5730\n",
      "Episode: 524/2000 , Avg Loss: 1319.0092, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.0418, STD: 0.5734\n",
      "Episode: 525/2000 , Avg Loss: 1365.3017, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.1262, STD: 0.5739\n",
      "Episode: 526/2000 , Avg Loss: 1112.7485, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.2008, STD: 0.5745\n",
      "Episode: 527/2000 , Avg Loss: 1395.4839, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.0619, STD: 0.5751\n",
      "Episode: 528/2000 , Avg Loss: 1081.0756, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3525, STD: 0.5758\n",
      "Episode: 529/2000 , Avg Loss: 1079.9647, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4383, STD: 0.5766\n",
      "Episode: 530/2000 , Avg Loss: 1302.6153, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2085, STD: 0.5771\n",
      "Episode: 531/2000 , Avg Loss: 1272.2244, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6980, STD: 0.5776\n",
      "Episode: 532/2000 , Avg Loss: 1160.1741, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7012, STD: 0.5782\n",
      "Episode: 533/2000 , Avg Loss: 1300.1236, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.7637, STD: 0.5786\n",
      "Episode: 534/2000 , Avg Loss: 1049.4472, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7587, STD: 0.5787\n",
      "Episode: 535/2000 , Avg Loss: 1325.7814, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6074, STD: 0.5789\n",
      "Episode: 536/2000 , Avg Loss: 1312.9782, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5479, STD: 0.5793\n",
      "Episode: 537/2000 , Avg Loss: 1255.8019, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8887, STD: 0.5799\n",
      "Episode: 538/2000 , Avg Loss: 1199.0992, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9103, STD: 0.5803\n",
      "Episode: 539/2000 , Avg Loss: 1181.3165, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8282, STD: 0.5808\n",
      "Episode: 540/2000 , Avg Loss: 1174.7437, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8001, STD: 0.5814\n",
      "Episode: 541/2000 , Avg Loss: 1487.7490, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6688, STD: 0.5819\n",
      "Episode: 542/2000 , Avg Loss: 1262.9612, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6607, STD: 0.5823\n",
      "Episode: 543/2000 , Avg Loss: 1234.8279, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.6855, STD: 0.5828\n",
      "Episode: 544/2000 , Avg Loss: 1220.0151, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6203, STD: 0.5831\n",
      "Episode: 545/2000 , Avg Loss: 1086.3511, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5043, STD: 0.5833\n",
      "Episode: 546/2000 , Avg Loss: 1550.2358, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6529, STD: 0.5835\n",
      "Episode: 547/2000 , Avg Loss: 1435.9089, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5466, STD: 0.5837\n",
      "Episode: 548/2000 , Avg Loss: 1227.4926, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4024, STD: 0.5840\n",
      "Episode: 549/2000 , Avg Loss: 1002.8895, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5958, STD: 0.5843\n",
      "Episode: 550/2000 , Avg Loss: 1341.4183, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6512, STD: 0.5846\n",
      "Episode: 551/2000 , Avg Loss: 1117.1654, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7894, STD: 0.5843\n",
      "Episode: 552/2000 , Avg Loss: 1312.8754, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6675, STD: 0.5840\n",
      "Episode: 553/2000 , Avg Loss: 1240.9925, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5423, STD: 0.5838\n",
      "Episode: 554/2000 , Avg Loss: 1170.8637, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6906, STD: 0.5836\n",
      "Episode: 555/2000 , Avg Loss: 1300.9036, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9317, STD: 0.5837\n",
      "Episode: 556/2000 , Avg Loss: 1326.6748, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8381, STD: 0.5838\n",
      "Episode: 557/2000 , Avg Loss: 1441.4323, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8546, STD: 0.5841\n",
      "Episode: 558/2000 , Avg Loss: 1358.5766, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8744, STD: 0.5842\n",
      "Episode: 559/2000 , Avg Loss: 1234.5256, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8524, STD: 0.5843\n",
      "Episode: 560/2000 , Avg Loss: 1118.7930, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7262, STD: 0.5846\n",
      "Episode: 561/2000 , Avg Loss: 1267.9765, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7102, STD: 0.5848\n",
      "Episode: 562/2000 , Avg Loss: 1535.3954, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7172, STD: 0.5854\n",
      "Episode: 563/2000 , Avg Loss: 1463.2807, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4529, STD: 0.5860\n",
      "Episode: 564/2000 , Avg Loss: 1334.6709, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4389, STD: 0.5867\n",
      "Episode: 565/2000 , Avg Loss: 1160.7474, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.3976, STD: 0.5872\n",
      "Episode: 566/2000 , Avg Loss: 1519.6007, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.4456, STD: 0.5877\n",
      "Episode: 567/2000 , Avg Loss: 1243.2441, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2393, STD: 0.5880\n",
      "Episode: 568/2000 , Avg Loss: 1476.6659, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3060, STD: 0.5883\n",
      "Episode: 569/2000 , Avg Loss: 1330.7467, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5479, STD: 0.5884\n",
      "Episode: 570/2000 , Avg Loss: 1478.6414, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.2560, STD: 0.5886\n",
      "Episode: 571/2000 , Avg Loss: 1197.1587, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.2694, STD: 0.5885\n",
      "Episode: 572/2000 , Avg Loss: 1168.2288, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.3947, STD: 0.5885\n",
      "Episode: 573/2000 , Avg Loss: 1242.4013, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4371, STD: 0.5886\n",
      "Episode: 574/2000 , Avg Loss: 1101.7604, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4165, STD: 0.5887\n",
      "Episode: 575/2000 , Avg Loss: 1223.7884, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.6685, STD: 0.5889\n",
      "Episode: 576/2000 , Avg Loss: 1069.4758, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7395, STD: 0.5892\n",
      "Episode: 577/2000 , Avg Loss: 1063.0690, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6831, STD: 0.5895\n",
      "Episode: 578/2000 , Avg Loss: 1203.3465, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7124, STD: 0.5897\n",
      "Episode: 579/2000 , Avg Loss: 1163.1255, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9592, STD: 0.5896\n",
      "Episode: 580/2000 , Avg Loss: 1349.0550, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8219, STD: 0.5892\n",
      "Episode: 581/2000 , Avg Loss: 1250.5266, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.7413, STD: 0.5892\n",
      "Episode: 582/2000 , Avg Loss: 1208.2290, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8001, STD: 0.5893\n",
      "Episode: 583/2000 , Avg Loss: 1265.2581, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7062, STD: 0.5893\n",
      "Episode: 584/2000 , Avg Loss: 1420.3766, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7064, STD: 0.5893\n",
      "Episode: 585/2000 , Avg Loss: 1221.0987, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8445, STD: 0.5889\n",
      "Episode: 586/2000 , Avg Loss: 1330.9078, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7226, STD: 0.5886\n",
      "Episode: 587/2000 , Avg Loss: 1328.1922, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6399, STD: 0.5887\n",
      "Episode: 588/2000 , Avg Loss: 1117.3647, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6907, STD: 0.5890\n",
      "Episode: 589/2000 , Avg Loss: 1346.4409, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.4251, STD: 0.5894\n",
      "Episode: 590/2000 , Avg Loss: 1482.3557, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5048, STD: 0.5895\n",
      "Episode: 591/2000 , Avg Loss: 1211.9937, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.4627, STD: 0.5894\n",
      "Episode: 592/2000 , Avg Loss: 1030.2383, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5616, STD: 0.5894\n",
      "Episode: 593/2000 , Avg Loss: 1026.6386, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4858, STD: 0.5897\n",
      "Episode: 594/2000 , Avg Loss: 1235.9981, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6483, STD: 0.5897\n",
      "Episode: 595/2000 , Avg Loss: 1186.3151, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.4990, STD: 0.5896\n",
      "Episode: 596/2000 , Avg Loss: 1142.1828, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6091, STD: 0.5898\n",
      "Episode: 597/2000 , Avg Loss: 1160.3275, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7522, STD: 0.5900\n",
      "Episode: 598/2000 , Avg Loss: 1400.6914, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5402, STD: 0.5902\n",
      "Episode: 599/2000 , Avg Loss: 1341.3638, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6776, STD: 0.5903\n",
      "Episode: 600/2000 , Avg Loss: 1051.2947, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.5610, STD: 0.5908\n",
      "Episode: 601/2000 , Avg Loss: 1136.2131, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5106, STD: 0.5914\n",
      "Episode: 602/2000 , Avg Loss: 1027.6085, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6790, STD: 0.5917\n",
      "Episode: 603/2000 , Avg Loss: 1271.4615, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.6087, STD: 0.5920\n",
      "Episode: 604/2000 , Avg Loss: 1203.3094, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8917, STD: 0.5923\n",
      "Episode: 605/2000 , Avg Loss: 1329.8610, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8573, STD: 0.5931\n",
      "Episode: 606/2000 , Avg Loss: 1071.0111, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7114, STD: 0.5934\n",
      "Episode: 607/2000 , Avg Loss: 1118.7242, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8795, STD: 0.5940\n",
      "Episode: 608/2000 , Avg Loss: 1356.1747, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7010, STD: 0.5945\n",
      "Episode: 609/2000 , Avg Loss: 1435.6848, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6954, STD: 0.5949\n",
      "Episode: 610/2000 , Avg Loss: 1227.8330, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8813, STD: 0.5950\n",
      "Episode: 611/2000 , Avg Loss: 1201.9496, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6180, STD: 0.5953\n",
      "Episode: 612/2000 , Avg Loss: 1445.7504, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0077, STD: 0.5956\n",
      "Episode: 613/2000 , Avg Loss: 1344.4213, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8721, STD: 0.5959\n",
      "Episode: 614/2000 , Avg Loss: 1178.1318, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6977, STD: 0.5964\n",
      "Episode: 615/2000 , Avg Loss: 844.1712, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.5628, STD: 0.5969\n",
      "Episode: 616/2000 , Avg Loss: 1243.5574, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6846, STD: 0.5975\n",
      "Episode: 617/2000 , Avg Loss: 1172.2938, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9321, STD: 0.5979\n",
      "Episode: 618/2000 , Avg Loss: 1299.5921, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.7497, STD: 0.5983\n",
      "Episode: 619/2000 , Avg Loss: 1380.2402, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.6746, STD: 0.5986\n",
      "Episode: 620/2000 , Avg Loss: 1195.1351, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5548, STD: 0.5988\n",
      "Episode: 621/2000 , Avg Loss: 1047.2576, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7370, STD: 0.5989\n",
      "Episode: 622/2000 , Avg Loss: 1200.9794, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.5182, STD: 0.5990\n",
      "Episode: 623/2000 , Avg Loss: 1140.9426, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6901, STD: 0.5991\n",
      "Episode: 624/2000 , Avg Loss: 1263.5224, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.4473, STD: 0.5990\n",
      "Episode: 625/2000 , Avg Loss: 1130.8621, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.7392, STD: 0.5989\n",
      "Episode: 626/2000 , Avg Loss: 1130.2577, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6199, STD: 0.5992\n",
      "Episode: 627/2000 , Avg Loss: 1236.6383, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.6476, STD: 0.5996\n",
      "Episode: 628/2000 , Avg Loss: 990.7424, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8202, STD: 0.6000\n",
      "Episode: 629/2000 , Avg Loss: 1143.4596, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7731, STD: 0.6004\n",
      "Episode: 630/2000 , Avg Loss: 1308.7670, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8617, STD: 0.6005\n",
      "Episode: 631/2000 , Avg Loss: 1008.2203, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.7727, STD: 0.6007\n",
      "Episode: 632/2000 , Avg Loss: 1271.5630, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.7618, STD: 0.6009\n",
      "Episode: 633/2000 , Avg Loss: 1242.2453, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8833, STD: 0.6011\n",
      "Episode: 634/2000 , Avg Loss: 1319.0000, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.9758, STD: 0.6010\n",
      "Episode: 635/2000 , Avg Loss: 950.2227, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9178, STD: 0.6011\n",
      "Episode: 636/2000 , Avg Loss: 1326.1768, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.9303, STD: 0.6013\n",
      "Episode: 637/2000 , Avg Loss: 1155.4378, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8362, STD: 0.6016\n",
      "Episode: 638/2000 , Avg Loss: 1015.1581, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.0848, STD: 0.6019\n",
      "Episode: 639/2000 , Avg Loss: 1373.7780, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8807, STD: 0.6023\n",
      "Episode: 640/2000 , Avg Loss: 1061.1106, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.0398, STD: 0.6026\n",
      "Episode: 641/2000 , Avg Loss: 1256.1647, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8785, STD: 0.6031\n",
      "Episode: 642/2000 , Avg Loss: 1274.2144, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1384, STD: 0.6036\n",
      "Episode: 643/2000 , Avg Loss: 1073.2125, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.1149, STD: 0.6043\n",
      "Episode: 644/2000 , Avg Loss: 1397.6919, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3820, STD: 0.6050\n",
      "Episode: 645/2000 , Avg Loss: 1450.4118, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3523, STD: 0.6056\n",
      "Episode: 646/2000 , Avg Loss: 1560.0561, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0885, STD: 0.6059\n",
      "Episode: 647/2000 , Avg Loss: 963.7279, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9430, STD: 0.6061\n",
      "Episode: 648/2000 , Avg Loss: 1122.8303, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8945, STD: 0.6059\n",
      "Episode: 649/2000 , Avg Loss: 1496.8938, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9031, STD: 0.6056\n",
      "Episode: 650/2000 , Avg Loss: 1183.3212, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8188, STD: 0.6057\n",
      "Episode: 651/2000 , Avg Loss: 1209.7103, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0114, STD: 0.6060\n",
      "Episode: 652/2000 , Avg Loss: 1416.9318, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0865, STD: 0.6064\n",
      "Episode: 653/2000 , Avg Loss: 1078.8478, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9148, STD: 0.6069\n",
      "Episode: 654/2000 , Avg Loss: 1371.8588, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.9260, STD: 0.6073\n",
      "Episode: 655/2000 , Avg Loss: 1378.4053, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9087, STD: 0.6076\n",
      "Episode: 656/2000 , Avg Loss: 1394.8091, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8796, STD: 0.6075\n",
      "Episode: 657/2000 , Avg Loss: 1127.4649, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 19.8991, STD: 0.6075\n",
      "Episode: 658/2000 , Avg Loss: 1137.8944, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8006, STD: 0.6075\n",
      "Episode: 659/2000 , Avg Loss: 1383.5215, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0481, STD: 0.6080\n",
      "Episode: 660/2000 , Avg Loss: 1322.7772, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9482, STD: 0.6083\n",
      "Episode: 661/2000 , Avg Loss: 1227.8831, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.0081, STD: 0.6086\n",
      "Episode: 662/2000 , Avg Loss: 1378.9203, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0647, STD: 0.6087\n",
      "Episode: 663/2000 , Avg Loss: 1243.2691, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.0445, STD: 0.6088\n",
      "Episode: 664/2000 , Avg Loss: 905.5314, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.0988, STD: 0.6089\n",
      "Episode: 665/2000 , Avg Loss: 1167.5527, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9916, STD: 0.6093\n",
      "Episode: 666/2000 , Avg Loss: 1357.0380, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2714, STD: 0.6099\n",
      "Episode: 667/2000 , Avg Loss: 1189.2546, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0942, STD: 0.6103\n",
      "Episode: 668/2000 , Avg Loss: 1258.3501, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1864, STD: 0.6107\n",
      "Episode: 669/2000 , Avg Loss: 1147.5878, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3706, STD: 0.6110\n",
      "Episode: 670/2000 , Avg Loss: 1168.3495, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.2713, STD: 0.6117\n",
      "Episode: 671/2000 , Avg Loss: 1137.7184, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3323, STD: 0.6122\n",
      "Episode: 672/2000 , Avg Loss: 1161.0238, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.4549, STD: 0.6123\n",
      "Episode: 673/2000 , Avg Loss: 1061.7676, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4064, STD: 0.6123\n",
      "Episode: 674/2000 , Avg Loss: 1452.6220, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.3231, STD: 0.6124\n",
      "Episode: 675/2000 , Avg Loss: 1452.0751, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.3075, STD: 0.6127\n",
      "Episode: 676/2000 , Avg Loss: 977.4495, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2097, STD: 0.6132\n",
      "Episode: 677/2000 , Avg Loss: 940.4396, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4958, STD: 0.6134\n",
      "Episode: 678/2000 , Avg Loss: 1241.9914, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.5839, STD: 0.6138\n",
      "Episode: 679/2000 , Avg Loss: 1203.5326, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5720, STD: 0.6143\n",
      "Episode: 680/2000 , Avg Loss: 1382.6274, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.5230, STD: 0.6148\n",
      "Episode: 681/2000 , Avg Loss: 1306.9142, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.5146, STD: 0.6151\n",
      "Episode: 682/2000 , Avg Loss: 1547.6349, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.3700, STD: 0.6155\n",
      "Episode: 683/2000 , Avg Loss: 1234.2193, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5003, STD: 0.6159\n",
      "Episode: 684/2000 , Avg Loss: 1271.2067, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.3224, STD: 0.6162\n",
      "Episode: 685/2000 , Avg Loss: 1242.6578, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.4494, STD: 0.6159\n",
      "Episode: 686/2000 , Avg Loss: 1253.2552, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1792, STD: 0.6163\n",
      "Episode: 687/2000 , Avg Loss: 1162.9741, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4499, STD: 0.6168\n",
      "Episode: 688/2000 , Avg Loss: 1106.8527, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.3620, STD: 0.6171\n",
      "Episode: 689/2000 , Avg Loss: 1320.8205, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.5601, STD: 0.6174\n",
      "Episode: 690/2000 , Avg Loss: 1470.0840, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5260, STD: 0.6178\n",
      "Episode: 691/2000 , Avg Loss: 1425.0407, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2182, STD: 0.6182\n",
      "Episode: 692/2000 , Avg Loss: 1127.3476, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5011, STD: 0.6188\n",
      "Episode: 693/2000 , Avg Loss: 1136.8966, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4426, STD: 0.6197\n",
      "Episode: 694/2000 , Avg Loss: 1395.4800, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.4498, STD: 0.6204\n",
      "Episode: 695/2000 , Avg Loss: 1280.1742, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.2300, STD: 0.6210\n",
      "Episode: 696/2000 , Avg Loss: 1108.3843, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2291, STD: 0.6217\n",
      "Episode: 697/2000 , Avg Loss: 1255.6747, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5444, STD: 0.6223\n",
      "Episode: 698/2000 , Avg Loss: 1189.8280, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.7891, STD: 0.6229\n",
      "Episode: 699/2000 , Avg Loss: 1245.4383, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6773, STD: 0.6233\n",
      "Episode: 700/2000 , Avg Loss: 1513.5566, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6618, STD: 0.6235\n",
      "Episode: 701/2000 , Avg Loss: 1025.5126, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8165, STD: 0.6238\n",
      "Episode: 702/2000 , Avg Loss: 1415.1226, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4966, STD: 0.6240\n",
      "Episode: 703/2000 , Avg Loss: 1058.9947, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7787, STD: 0.6244\n",
      "Episode: 704/2000 , Avg Loss: 1426.8652, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7293, STD: 0.6249\n",
      "Episode: 705/2000 , Avg Loss: 1359.1850, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6826, STD: 0.6254\n",
      "Episode: 706/2000 , Avg Loss: 1307.5488, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8969, STD: 0.6258\n",
      "Episode: 707/2000 , Avg Loss: 1344.0265, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7786, STD: 0.6261\n",
      "Episode: 708/2000 , Avg Loss: 1272.2475, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5256, STD: 0.6266\n",
      "Episode: 709/2000 , Avg Loss: 1381.8556, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6309, STD: 0.6269\n",
      "Episode: 710/2000 , Avg Loss: 1395.3186, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6986, STD: 0.6273\n",
      "Episode: 711/2000 , Avg Loss: 1364.2936, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5846, STD: 0.6285\n",
      "Episode: 712/2000 , Avg Loss: 1309.0836, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8005, STD: 0.6295\n",
      "Episode: 713/2000 , Avg Loss: 1224.8354, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4768, STD: 0.6303\n",
      "Episode: 714/2000 , Avg Loss: 1414.3251, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.6803, STD: 0.6312\n",
      "Episode: 715/2000 , Avg Loss: 1366.1289, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6204, STD: 0.6319\n",
      "Episode: 716/2000 , Avg Loss: 1385.5067, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3701, STD: 0.6327\n",
      "Episode: 717/2000 , Avg Loss: 1076.4919, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3929, STD: 0.6332\n",
      "Episode: 718/2000 , Avg Loss: 1405.6614, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4929, STD: 0.6339\n",
      "Episode: 719/2000 , Avg Loss: 1486.2516, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.5197, STD: 0.6346\n",
      "Episode: 720/2000 , Avg Loss: 1192.8945, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7602, STD: 0.6353\n",
      "Episode: 721/2000 , Avg Loss: 1091.9394, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5029, STD: 0.6360\n",
      "Episode: 722/2000 , Avg Loss: 1015.2959, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3962, STD: 0.6367\n",
      "Episode: 723/2000 , Avg Loss: 1234.6109, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5705, STD: 0.6374\n",
      "Episode: 724/2000 , Avg Loss: 1025.3661, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5345, STD: 0.6384\n",
      "Episode: 725/2000 , Avg Loss: 1160.7718, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5946, STD: 0.6391\n",
      "Episode: 726/2000 , Avg Loss: 1371.2382, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8368, STD: 0.6396\n",
      "Episode: 727/2000 , Avg Loss: 1331.5329, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8657, STD: 0.6402\n",
      "Episode: 728/2000 , Avg Loss: 1275.0479, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8212, STD: 0.6405\n",
      "Episode: 729/2000 , Avg Loss: 1036.3500, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.9107, STD: 0.6408\n",
      "Episode: 730/2000 , Avg Loss: 1516.1523, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8445, STD: 0.6410\n",
      "Episode: 731/2000 , Avg Loss: 1210.0614, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.7436, STD: 0.6413\n",
      "Episode: 732/2000 , Avg Loss: 1492.1665, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7853, STD: 0.6420\n",
      "Episode: 733/2000 , Avg Loss: 1523.7216, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6103, STD: 0.6424\n",
      "Episode: 734/2000 , Avg Loss: 1360.9927, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6393, STD: 0.6426\n",
      "Episode: 735/2000 , Avg Loss: 1254.1552, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5488, STD: 0.6430\n",
      "Episode: 736/2000 , Avg Loss: 1322.5280, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8013, STD: 0.6436\n",
      "Episode: 737/2000 , Avg Loss: 1194.0619, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5384, STD: 0.6442\n",
      "Episode: 738/2000 , Avg Loss: 1639.0264, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6010, STD: 0.6447\n",
      "Episode: 739/2000 , Avg Loss: 1389.4193, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5979, STD: 0.6452\n",
      "Episode: 740/2000 , Avg Loss: 1325.1732, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5322, STD: 0.6456\n",
      "Episode: 741/2000 , Avg Loss: 1314.2784, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7199, STD: 0.6461\n",
      "Episode: 742/2000 , Avg Loss: 1464.7037, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3143, STD: 0.6467\n",
      "Episode: 743/2000 , Avg Loss: 1217.0896, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3295, STD: 0.6471\n",
      "Episode: 744/2000 , Avg Loss: 1585.2142, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2673, STD: 0.6474\n",
      "Episode: 745/2000 , Avg Loss: 1319.3707, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4439, STD: 0.6478\n",
      "Episode: 746/2000 , Avg Loss: 1405.6772, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3534, STD: 0.6483\n",
      "Episode: 747/2000 , Avg Loss: 1335.8173, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3390, STD: 0.6489\n",
      "Episode: 748/2000 , Avg Loss: 1197.4906, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3273, STD: 0.6498\n",
      "Episode: 749/2000 , Avg Loss: 1160.3084, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2943, STD: 0.6507\n",
      "Episode: 750/2000 , Avg Loss: 1472.6181, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3244, STD: 0.6511\n",
      "Episode: 751/2000 , Avg Loss: 1106.2894, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4945, STD: 0.6510\n",
      "Episode: 752/2000 , Avg Loss: 1074.8765, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5620, STD: 0.6513\n",
      "Episode: 753/2000 , Avg Loss: 1527.3433, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6292, STD: 0.6517\n",
      "Episode: 754/2000 , Avg Loss: 1162.2725, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5723, STD: 0.6524\n",
      "Episode: 755/2000 , Avg Loss: 1230.8672, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7440, STD: 0.6529\n",
      "Episode: 756/2000 , Avg Loss: 1290.5245, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7052, STD: 0.6534\n",
      "Episode: 757/2000 , Avg Loss: 1361.8984, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7259, STD: 0.6541\n",
      "Episode: 758/2000 , Avg Loss: 1655.3557, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4716, STD: 0.6549\n",
      "Episode: 759/2000 , Avg Loss: 1378.1591, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5899, STD: 0.6558\n",
      "Episode: 760/2000 , Avg Loss: 1480.2886, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5199, STD: 0.6566\n",
      "Episode: 761/2000 , Avg Loss: 1292.8732, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4806, STD: 0.6573\n",
      "Episode: 762/2000 , Avg Loss: 1386.1333, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3056, STD: 0.6581\n",
      "Episode: 763/2000 , Avg Loss: 1465.5508, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4110, STD: 0.6587\n",
      "Episode: 764/2000 , Avg Loss: 1148.1370, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1450, STD: 0.6593\n",
      "Episode: 765/2000 , Avg Loss: 1485.5627, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2475, STD: 0.6600\n",
      "Episode: 766/2000 , Avg Loss: 1359.6464, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2436, STD: 0.6608\n",
      "Episode: 767/2000 , Avg Loss: 1010.4528, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2216, STD: 0.6615\n",
      "Episode: 768/2000 , Avg Loss: 1279.7660, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5365, STD: 0.6621\n",
      "Episode: 769/2000 , Avg Loss: 1439.1225, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2870, STD: 0.6626\n",
      "Episode: 770/2000 , Avg Loss: 1408.4151, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3207, STD: 0.6633\n",
      "Episode: 771/2000 , Avg Loss: 1234.0448, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.6043, STD: 0.6643\n",
      "Episode: 772/2000 , Avg Loss: 1500.6008, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4882, STD: 0.6652\n",
      "Episode: 773/2000 , Avg Loss: 1422.6481, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6274, STD: 0.6654\n",
      "Episode: 774/2000 , Avg Loss: 1598.9300, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5371, STD: 0.6659\n",
      "Episode: 775/2000 , Avg Loss: 1055.4649, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4983, STD: 0.6665\n",
      "Episode: 776/2000 , Avg Loss: 1457.7582, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4301, STD: 0.6675\n",
      "Episode: 777/2000 , Avg Loss: 1336.1869, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4729, STD: 0.6684\n",
      "Episode: 778/2000 , Avg Loss: 1055.4911, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3394, STD: 0.6696\n",
      "Episode: 779/2000 , Avg Loss: 942.3092, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4448, STD: 0.6705\n",
      "Episode: 780/2000 , Avg Loss: 1289.6007, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5426, STD: 0.6712\n",
      "Episode: 781/2000 , Avg Loss: 1211.0454, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6466, STD: 0.6721\n",
      "Episode: 782/2000 , Avg Loss: 1285.5758, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5636, STD: 0.6729\n",
      "Episode: 783/2000 , Avg Loss: 1179.4175, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6559, STD: 0.6740\n",
      "Episode: 784/2000 , Avg Loss: 1192.0498, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6963, STD: 0.6751\n",
      "Episode: 785/2000 , Avg Loss: 1052.6398, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7395, STD: 0.6761\n",
      "Episode: 786/2000 , Avg Loss: 1395.2156, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6593, STD: 0.6770\n",
      "Episode: 787/2000 , Avg Loss: 1600.0257, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.8167, STD: 0.6778\n",
      "Episode: 788/2000 , Avg Loss: 1294.2340, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.9002, STD: 0.6786\n",
      "Episode: 789/2000 , Avg Loss: 1400.0224, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.7405, STD: 0.6790\n",
      "Episode: 790/2000 , Avg Loss: 1392.4152, Eigenval: 3.0000, Neighbor: 25.0000, Mean: 20.7406, STD: 0.6795\n",
      "Episode: 791/2000 , Avg Loss: 1296.5461, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.6158, STD: 0.6799\n",
      "Episode: 792/2000 , Avg Loss: 952.1558, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6804, STD: 0.6803\n",
      "Episode: 793/2000 , Avg Loss: 1265.3916, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6408, STD: 0.6808\n",
      "Episode: 794/2000 , Avg Loss: 1417.6983, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6545, STD: 0.6814\n",
      "Episode: 795/2000 , Avg Loss: 1143.0612, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7045, STD: 0.6821\n",
      "Episode: 796/2000 , Avg Loss: 1171.5691, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6405, STD: 0.6827\n",
      "Episode: 797/2000 , Avg Loss: 1385.2014, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5056, STD: 0.6833\n",
      "Episode: 798/2000 , Avg Loss: 1311.2497, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4519, STD: 0.6842\n",
      "Episode: 799/2000 , Avg Loss: 1255.3988, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5301, STD: 0.6851\n",
      "Episode: 800/2000 , Avg Loss: 1479.0546, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2933, STD: 0.6858\n",
      "Episode: 801/2000 , Avg Loss: 1312.4709, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4667, STD: 0.6863\n",
      "Episode: 802/2000 , Avg Loss: 1273.8351, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3880, STD: 0.6871\n",
      "Episode: 803/2000 , Avg Loss: 1254.3328, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3053, STD: 0.6877\n",
      "Episode: 804/2000 , Avg Loss: 1074.7826, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4635, STD: 0.6886\n",
      "Episode: 805/2000 , Avg Loss: 1470.3716, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6158, STD: 0.6893\n",
      "Episode: 806/2000 , Avg Loss: 1129.2658, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6032, STD: 0.6899\n",
      "Episode: 807/2000 , Avg Loss: 1367.6124, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4582, STD: 0.6904\n",
      "Episode: 808/2000 , Avg Loss: 1601.4050, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3721, STD: 0.6906\n",
      "Episode: 809/2000 , Avg Loss: 1276.3347, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4385, STD: 0.6910\n",
      "Episode: 810/2000 , Avg Loss: 1437.7754, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1753, STD: 0.6915\n",
      "Episode: 811/2000 , Avg Loss: 1168.8637, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3041, STD: 0.6924\n",
      "Episode: 812/2000 , Avg Loss: 1331.1379, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4484, STD: 0.6934\n",
      "Episode: 813/2000 , Avg Loss: 1227.0086, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4149, STD: 0.6941\n",
      "Episode: 814/2000 , Avg Loss: 1628.2025, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4642, STD: 0.6944\n",
      "Episode: 815/2000 , Avg Loss: 1492.4768, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2567, STD: 0.6946\n",
      "Episode: 816/2000 , Avg Loss: 1307.5657, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3136, STD: 0.6949\n",
      "Episode: 817/2000 , Avg Loss: 1006.1831, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3133, STD: 0.6953\n",
      "Episode: 818/2000 , Avg Loss: 1344.1059, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3458, STD: 0.6958\n",
      "Episode: 819/2000 , Avg Loss: 1400.3654, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4104, STD: 0.6964\n",
      "Episode: 820/2000 , Avg Loss: 1506.4285, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5606, STD: 0.6970\n",
      "Episode: 821/2000 , Avg Loss: 1142.4518, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5285, STD: 0.6980\n",
      "Episode: 822/2000 , Avg Loss: 1188.0453, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5961, STD: 0.6988\n",
      "Episode: 823/2000 , Avg Loss: 1305.4537, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5050, STD: 0.6995\n",
      "Episode: 824/2000 , Avg Loss: 1388.2941, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4852, STD: 0.7003\n",
      "Episode: 825/2000 , Avg Loss: 1120.0484, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5991, STD: 0.7011\n",
      "Episode: 826/2000 , Avg Loss: 1551.3363, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5630, STD: 0.7015\n",
      "Episode: 827/2000 , Avg Loss: 1257.8451, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4425, STD: 0.7018\n",
      "Episode: 828/2000 , Avg Loss: 1424.6463, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4157, STD: 0.7019\n",
      "Episode: 829/2000 , Avg Loss: 1088.3913, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4945, STD: 0.7022\n",
      "Episode: 830/2000 , Avg Loss: 1426.6356, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3448, STD: 0.7026\n",
      "Episode: 831/2000 , Avg Loss: 1359.7671, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2438, STD: 0.7030\n",
      "Episode: 832/2000 , Avg Loss: 1457.8995, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2690, STD: 0.7037\n",
      "Episode: 833/2000 , Avg Loss: 1244.6776, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2140, STD: 0.7045\n",
      "Episode: 834/2000 , Avg Loss: 1378.1775, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3810, STD: 0.7056\n",
      "Episode: 835/2000 , Avg Loss: 1649.9645, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3344, STD: 0.7065\n",
      "Episode: 836/2000 , Avg Loss: 1490.7542, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3688, STD: 0.7072\n",
      "Episode: 837/2000 , Avg Loss: 1306.4129, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0270, STD: 0.7079\n",
      "Episode: 838/2000 , Avg Loss: 1377.0763, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2964, STD: 0.7086\n",
      "Episode: 839/2000 , Avg Loss: 1483.6513, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9687, STD: 0.7092\n",
      "Episode: 840/2000 , Avg Loss: 1546.7496, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1060, STD: 0.7102\n",
      "Episode: 841/2000 , Avg Loss: 1285.8612, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0630, STD: 0.7109\n",
      "Episode: 842/2000 , Avg Loss: 1335.2989, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9801, STD: 0.7118\n",
      "Episode: 843/2000 , Avg Loss: 1369.9613, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2862, STD: 0.7125\n",
      "Episode: 844/2000 , Avg Loss: 1291.3193, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1458, STD: 0.7131\n",
      "Episode: 845/2000 , Avg Loss: 1299.3361, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1190, STD: 0.7137\n",
      "Episode: 846/2000 , Avg Loss: 1332.0234, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2181, STD: 0.7142\n",
      "Episode: 847/2000 , Avg Loss: 1403.6844, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2045, STD: 0.7145\n",
      "Episode: 848/2000 , Avg Loss: 1434.9485, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1605, STD: 0.7148\n",
      "Episode: 849/2000 , Avg Loss: 1293.4834, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0148, STD: 0.7152\n",
      "Episode: 850/2000 , Avg Loss: 1304.2271, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2885, STD: 0.7159\n",
      "Episode: 851/2000 , Avg Loss: 1293.8203, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0684, STD: 0.7166\n",
      "Episode: 852/2000 , Avg Loss: 1514.1713, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0421, STD: 0.7170\n",
      "Episode: 853/2000 , Avg Loss: 1245.8716, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9690, STD: 0.7179\n",
      "Episode: 854/2000 , Avg Loss: 1268.2115, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9998, STD: 0.7186\n",
      "Episode: 855/2000 , Avg Loss: 987.0447, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9047, STD: 0.7193\n",
      "Episode: 856/2000 , Avg Loss: 1203.9040, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0786, STD: 0.7200\n",
      "Episode: 857/2000 , Avg Loss: 1242.4676, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.8235, STD: 0.7206\n",
      "Episode: 858/2000 , Avg Loss: 1305.7072, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2064, STD: 0.7214\n",
      "Episode: 859/2000 , Avg Loss: 1353.4899, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0497, STD: 0.7224\n",
      "Episode: 860/2000 , Avg Loss: 1389.3892, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0375, STD: 0.7235\n",
      "Episode: 861/2000 , Avg Loss: 1436.7099, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2009, STD: 0.7247\n",
      "Episode: 862/2000 , Avg Loss: 1353.1382, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0660, STD: 0.7256\n",
      "Episode: 863/2000 , Avg Loss: 1105.7605, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9499, STD: 0.7263\n",
      "Episode: 864/2000 , Avg Loss: 962.0306, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1305, STD: 0.7268\n",
      "Episode: 865/2000 , Avg Loss: 1361.9927, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0612, STD: 0.7273\n",
      "Episode: 866/2000 , Avg Loss: 1257.9065, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0690, STD: 0.7280\n",
      "Episode: 867/2000 , Avg Loss: 1486.1803, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2348, STD: 0.7287\n",
      "Episode: 868/2000 , Avg Loss: 1267.6622, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1885, STD: 0.7294\n",
      "Episode: 869/2000 , Avg Loss: 1426.8975, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0950, STD: 0.7301\n",
      "Episode: 870/2000 , Avg Loss: 1178.3078, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0948, STD: 0.7306\n",
      "Episode: 871/2000 , Avg Loss: 1600.0045, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2629, STD: 0.7310\n",
      "Episode: 872/2000 , Avg Loss: 1150.4685, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1088, STD: 0.7311\n",
      "Episode: 873/2000 , Avg Loss: 1514.1351, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0664, STD: 0.7313\n",
      "Episode: 874/2000 , Avg Loss: 1319.0210, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0860, STD: 0.7318\n",
      "Episode: 875/2000 , Avg Loss: 1216.3892, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1049, STD: 0.7325\n",
      "Episode: 876/2000 , Avg Loss: 1350.3129, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0206, STD: 0.7331\n",
      "Episode: 877/2000 , Avg Loss: 1044.8171, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1479, STD: 0.7334\n",
      "Episode: 878/2000 , Avg Loss: 1656.5582, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0321, STD: 0.7338\n",
      "Episode: 879/2000 , Avg Loss: 1115.6356, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1644, STD: 0.7344\n",
      "Episode: 880/2000 , Avg Loss: 1104.7574, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1176, STD: 0.7353\n",
      "Episode: 881/2000 , Avg Loss: 1301.1741, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1924, STD: 0.7362\n",
      "Episode: 882/2000 , Avg Loss: 1339.1798, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4407, STD: 0.7372\n",
      "Episode: 883/2000 , Avg Loss: 1433.5509, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1686, STD: 0.7381\n",
      "Episode: 884/2000 , Avg Loss: 1273.1155, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4588, STD: 0.7393\n",
      "Episode: 885/2000 , Avg Loss: 1167.3459, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2759, STD: 0.7402\n",
      "Episode: 886/2000 , Avg Loss: 1554.5865, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4543, STD: 0.7415\n",
      "Episode: 887/2000 , Avg Loss: 1118.8969, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2660, STD: 0.7426\n",
      "Episode: 888/2000 , Avg Loss: 1420.8302, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2275, STD: 0.7437\n",
      "Episode: 889/2000 , Avg Loss: 1556.3747, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1974, STD: 0.7446\n",
      "Episode: 890/2000 , Avg Loss: 1565.0641, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3696, STD: 0.7451\n",
      "Episode: 891/2000 , Avg Loss: 1276.0991, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2184, STD: 0.7456\n",
      "Episode: 892/2000 , Avg Loss: 1361.4067, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1131, STD: 0.7459\n",
      "Episode: 893/2000 , Avg Loss: 1435.2189, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2018, STD: 0.7468\n",
      "Episode: 894/2000 , Avg Loss: 1308.6046, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0925, STD: 0.7480\n",
      "Episode: 895/2000 , Avg Loss: 1203.0244, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2147, STD: 0.7494\n",
      "Episode: 896/2000 , Avg Loss: 1088.6930, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0291, STD: 0.7506\n",
      "Episode: 897/2000 , Avg Loss: 1199.2129, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1964, STD: 0.7516\n",
      "Episode: 898/2000 , Avg Loss: 1457.6490, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4740, STD: 0.7528\n",
      "Episode: 899/2000 , Avg Loss: 1395.0305, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2085, STD: 0.7538\n",
      "Episode: 900/2000 , Avg Loss: 1210.3724, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3906, STD: 0.7547\n",
      "Episode: 901/2000 , Avg Loss: 1201.4730, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5428, STD: 0.7558\n",
      "Episode: 902/2000 , Avg Loss: 1415.5693, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4497, STD: 0.7569\n",
      "Episode: 903/2000 , Avg Loss: 1340.1384, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.7185, STD: 0.7579\n",
      "Episode: 904/2000 , Avg Loss: 1254.9136, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4977, STD: 0.7589\n",
      "Episode: 905/2000 , Avg Loss: 1385.0120, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6423, STD: 0.7600\n",
      "Episode: 906/2000 , Avg Loss: 1153.6836, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.7022, STD: 0.7607\n",
      "Episode: 907/2000 , Avg Loss: 1251.1976, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5546, STD: 0.7615\n",
      "Episode: 908/2000 , Avg Loss: 1252.7983, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4611, STD: 0.7625\n",
      "Episode: 909/2000 , Avg Loss: 1453.0968, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5055, STD: 0.7636\n",
      "Episode: 910/2000 , Avg Loss: 1314.2178, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5521, STD: 0.7647\n",
      "Episode: 911/2000 , Avg Loss: 1461.5293, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5254, STD: 0.7660\n",
      "Episode: 912/2000 , Avg Loss: 1266.7880, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5370, STD: 0.7669\n",
      "Episode: 913/2000 , Avg Loss: 1294.1261, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5412, STD: 0.7678\n",
      "Episode: 914/2000 , Avg Loss: 1621.4258, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5047, STD: 0.7686\n",
      "Episode: 915/2000 , Avg Loss: 1380.5372, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3931, STD: 0.7697\n",
      "Episode: 916/2000 , Avg Loss: 1303.7488, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5147, STD: 0.7707\n",
      "Episode: 917/2000 , Avg Loss: 1284.1112, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3508, STD: 0.7718\n",
      "Episode: 918/2000 , Avg Loss: 1363.6162, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2915, STD: 0.7729\n",
      "Episode: 919/2000 , Avg Loss: 1211.4769, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4416, STD: 0.7737\n",
      "Episode: 920/2000 , Avg Loss: 1317.0472, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3161, STD: 0.7746\n",
      "Episode: 921/2000 , Avg Loss: 1330.4624, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4042, STD: 0.7755\n",
      "Episode: 922/2000 , Avg Loss: 1472.4628, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3567, STD: 0.7764\n",
      "Episode: 923/2000 , Avg Loss: 1507.7398, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3072, STD: 0.7771\n",
      "Episode: 924/2000 , Avg Loss: 1206.0090, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1066, STD: 0.7778\n",
      "Episode: 925/2000 , Avg Loss: 1679.9563, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2358, STD: 0.7786\n",
      "Episode: 926/2000 , Avg Loss: 1493.3763, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1770, STD: 0.7796\n",
      "Episode: 927/2000 , Avg Loss: 1470.5587, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3507, STD: 0.7809\n",
      "Episode: 928/2000 , Avg Loss: 1565.5716, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0974, STD: 0.7821\n",
      "Episode: 929/2000 , Avg Loss: 1360.8427, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2927, STD: 0.7830\n",
      "Episode: 930/2000 , Avg Loss: 1426.6291, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1619, STD: 0.7841\n",
      "Episode: 931/2000 , Avg Loss: 1128.5434, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3346, STD: 0.7851\n",
      "Episode: 932/2000 , Avg Loss: 1071.2432, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2792, STD: 0.7862\n",
      "Episode: 933/2000 , Avg Loss: 1394.6360, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3806, STD: 0.7871\n",
      "Episode: 934/2000 , Avg Loss: 1123.3115, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4033, STD: 0.7879\n",
      "Episode: 935/2000 , Avg Loss: 1441.4269, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6656, STD: 0.7887\n",
      "Episode: 936/2000 , Avg Loss: 1714.8909, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5391, STD: 0.7895\n",
      "Episode: 937/2000 , Avg Loss: 1174.0338, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3644, STD: 0.7902\n",
      "Episode: 938/2000 , Avg Loss: 1192.9807, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4475, STD: 0.7910\n",
      "Episode: 939/2000 , Avg Loss: 1226.1787, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.5290, STD: 0.7919\n",
      "Episode: 940/2000 , Avg Loss: 1434.4638, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.6026, STD: 0.7929\n",
      "Episode: 941/2000 , Avg Loss: 1306.9558, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4711, STD: 0.7941\n",
      "Episode: 942/2000 , Avg Loss: 1320.5362, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4757, STD: 0.7954\n",
      "Episode: 943/2000 , Avg Loss: 1358.9656, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.4240, STD: 0.7964\n",
      "Episode: 944/2000 , Avg Loss: 1645.6459, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5607, STD: 0.7971\n",
      "Episode: 945/2000 , Avg Loss: 1383.4958, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4563, STD: 0.7977\n",
      "Episode: 946/2000 , Avg Loss: 1652.2531, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3778, STD: 0.7984\n",
      "Episode: 947/2000 , Avg Loss: 1401.2652, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3075, STD: 0.7995\n",
      "Episode: 948/2000 , Avg Loss: 1325.9890, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3072, STD: 0.8005\n",
      "Episode: 949/2000 , Avg Loss: 1251.6089, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2617, STD: 0.8013\n",
      "Episode: 950/2000 , Avg Loss: 1387.0732, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2829, STD: 0.8028\n",
      "Episode: 951/2000 , Avg Loss: 1537.7762, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3102, STD: 0.8045\n",
      "Episode: 952/2000 , Avg Loss: 1213.9197, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4413, STD: 0.8061\n",
      "Episode: 953/2000 , Avg Loss: 1496.6593, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4599, STD: 0.8079\n",
      "Episode: 954/2000 , Avg Loss: 1285.1423, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3620, STD: 0.8091\n",
      "Episode: 955/2000 , Avg Loss: 1695.5749, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4196, STD: 0.8099\n",
      "Episode: 956/2000 , Avg Loss: 1442.1335, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2344, STD: 0.8106\n",
      "Episode: 957/2000 , Avg Loss: 1268.3520, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4234, STD: 0.8115\n",
      "Episode: 958/2000 , Avg Loss: 1445.7085, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3731, STD: 0.8125\n",
      "Episode: 959/2000 , Avg Loss: 1263.0918, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1007, STD: 0.8135\n",
      "Episode: 960/2000 , Avg Loss: 1408.3447, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3107, STD: 0.8146\n",
      "Episode: 961/2000 , Avg Loss: 1217.6786, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1869, STD: 0.8154\n",
      "Episode: 962/2000 , Avg Loss: 1666.4160, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2926, STD: 0.8161\n",
      "Episode: 963/2000 , Avg Loss: 1490.4227, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2299, STD: 0.8170\n",
      "Episode: 964/2000 , Avg Loss: 1298.1351, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1581, STD: 0.8182\n",
      "Episode: 965/2000 , Avg Loss: 1425.2186, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2067, STD: 0.8200\n",
      "Episode: 966/2000 , Avg Loss: 1602.2815, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0923, STD: 0.8217\n",
      "Episode: 967/2000 , Avg Loss: 1519.8009, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9587, STD: 0.8232\n",
      "Episode: 968/2000 , Avg Loss: 1635.5272, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9459, STD: 0.8245\n",
      "Episode: 969/2000 , Avg Loss: 1651.0535, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8962, STD: 0.8260\n",
      "Episode: 970/2000 , Avg Loss: 1550.8478, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.6224, STD: 0.8275\n",
      "Episode: 971/2000 , Avg Loss: 1548.5117, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.7530, STD: 0.8290\n",
      "Episode: 972/2000 , Avg Loss: 1318.1060, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9277, STD: 0.8304\n",
      "Episode: 973/2000 , Avg Loss: 1361.7431, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8432, STD: 0.8317\n",
      "Episode: 974/2000 , Avg Loss: 1419.8205, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.8734, STD: 0.8326\n",
      "Episode: 975/2000 , Avg Loss: 1493.3560, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0007, STD: 0.8337\n",
      "Episode: 976/2000 , Avg Loss: 1226.4620, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0706, STD: 0.8348\n",
      "Episode: 977/2000 , Avg Loss: 1281.7574, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0380, STD: 0.8360\n",
      "Episode: 978/2000 , Avg Loss: 1108.1910, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0209, STD: 0.8370\n",
      "Episode: 979/2000 , Avg Loss: 1523.7585, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2846, STD: 0.8379\n",
      "Episode: 980/2000 , Avg Loss: 1315.4749, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1532, STD: 0.8386\n",
      "Episode: 981/2000 , Avg Loss: 1412.2966, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0909, STD: 0.8395\n",
      "Episode: 982/2000 , Avg Loss: 1452.6761, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1658, STD: 0.8405\n",
      "Episode: 983/2000 , Avg Loss: 1458.1641, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.0521, STD: 0.8415\n",
      "Episode: 984/2000 , Avg Loss: 1118.3460, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1683, STD: 0.8425\n",
      "Episode: 985/2000 , Avg Loss: 1429.8536, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1028, STD: 0.8438\n",
      "Episode: 986/2000 , Avg Loss: 1391.7857, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.2211, STD: 0.8448\n",
      "Episode: 987/2000 , Avg Loss: 1706.6264, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1949, STD: 0.8456\n",
      "Episode: 988/2000 , Avg Loss: 1598.6008, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 19.9766, STD: 0.8463\n",
      "Episode: 989/2000 , Avg Loss: 1233.7933, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0611, STD: 0.8470\n",
      "Episode: 990/2000 , Avg Loss: 1541.4086, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0709, STD: 0.8480\n",
      "Episode: 991/2000 , Avg Loss: 1637.9989, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9737, STD: 0.8488\n",
      "Episode: 992/2000 , Avg Loss: 1300.3583, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9370, STD: 0.8496\n",
      "Episode: 993/2000 , Avg Loss: 1273.1297, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0687, STD: 0.8504\n",
      "Episode: 994/2000 , Avg Loss: 1347.6900, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0290, STD: 0.8512\n",
      "Episode: 995/2000 , Avg Loss: 1317.2247, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.1025, STD: 0.8521\n",
      "Episode: 996/2000 , Avg Loss: 1534.2724, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0911, STD: 0.8531\n",
      "Episode: 997/2000 , Avg Loss: 1499.8350, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1659, STD: 0.8540\n",
      "Episode: 998/2000 , Avg Loss: 1220.2382, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1456, STD: 0.8548\n",
      "Episode: 999/2000 , Avg Loss: 1390.5414, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0623, STD: 0.8562\n",
      "Episode: 1000/2000 , Avg Loss: 1354.8521, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1261, STD: 0.8577\n",
      "Episode: 1001/2000 , Avg Loss: 1381.5064, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1653, STD: 0.8590\n",
      "Episode: 1002/2000 , Avg Loss: 1694.0340, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9989, STD: 0.8603\n",
      "Episode: 1003/2000 , Avg Loss: 1225.1042, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 19.9675, STD: 0.8616\n",
      "Episode: 1004/2000 , Avg Loss: 1408.5714, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1306, STD: 0.8628\n",
      "Episode: 1005/2000 , Avg Loss: 1272.6109, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1493, STD: 0.8640\n",
      "Episode: 1006/2000 , Avg Loss: 1615.9260, Eigenval: 4.0000, Neighbor: 20.0000, Mean: 20.3110, STD: 0.8648\n",
      "Episode: 1007/2000 , Avg Loss: 1258.4063, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1858, STD: 0.8654\n",
      "Episode: 1008/2000 , Avg Loss: 1134.7323, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2265, STD: 0.8660\n",
      "Episode: 1009/2000 , Avg Loss: 1169.6539, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1242, STD: 0.8668\n",
      "Episode: 1010/2000 , Avg Loss: 1579.7505, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1736, STD: 0.8681\n",
      "Episode: 1011/2000 , Avg Loss: 1219.7515, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3632, STD: 0.8692\n",
      "Episode: 1012/2000 , Avg Loss: 1254.2937, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2016, STD: 0.8702\n",
      "Episode: 1013/2000 , Avg Loss: 1369.4703, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3035, STD: 0.8713\n",
      "Episode: 1014/2000 , Avg Loss: 1368.1349, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2953, STD: 0.8726\n",
      "Episode: 1015/2000 , Avg Loss: 1381.6531, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1421, STD: 0.8740\n",
      "Episode: 1016/2000 , Avg Loss: 1054.6749, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1549, STD: 0.8753\n",
      "Episode: 1017/2000 , Avg Loss: 1289.0484, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2344, STD: 0.8763\n",
      "Episode: 1018/2000 , Avg Loss: 1328.5500, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2103, STD: 0.8772\n",
      "Episode: 1019/2000 , Avg Loss: 1391.1302, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2756, STD: 0.8781\n",
      "Episode: 1020/2000 , Avg Loss: 1231.3221, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1850, STD: 0.8791\n",
      "Episode: 1021/2000 , Avg Loss: 1438.7850, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.0697, STD: 0.8800\n",
      "Episode: 1022/2000 , Avg Loss: 1630.9370, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1961, STD: 0.8809\n",
      "Episode: 1023/2000 , Avg Loss: 1076.2665, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1215, STD: 0.8821\n",
      "Episode: 1024/2000 , Avg Loss: 1183.6686, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2276, STD: 0.8831\n",
      "Episode: 1025/2000 , Avg Loss: 1544.2330, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2662, STD: 0.8841\n",
      "Episode: 1026/2000 , Avg Loss: 1578.1890, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2704, STD: 0.8854\n",
      "Episode: 1027/2000 , Avg Loss: 1028.8171, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.1642, STD: 0.8867\n",
      "Episode: 1028/2000 , Avg Loss: 1290.6172, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4238, STD: 0.8880\n",
      "Episode: 1029/2000 , Avg Loss: 1331.6730, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4427, STD: 0.8891\n",
      "Episode: 1030/2000 , Avg Loss: 1596.5734, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.5166, STD: 0.8900\n",
      "Episode: 1031/2000 , Avg Loss: 1162.8602, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.6587, STD: 0.8906\n",
      "Episode: 1032/2000 , Avg Loss: 1658.1803, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.6284, STD: 0.8912\n",
      "Episode: 1033/2000 , Avg Loss: 1371.8814, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4137, STD: 0.8919\n",
      "Episode: 1034/2000 , Avg Loss: 1176.7853, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.4363, STD: 0.8930\n",
      "Episode: 1035/2000 , Avg Loss: 1778.6401, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3704, STD: 0.8942\n",
      "Episode: 1036/2000 , Avg Loss: 1093.6632, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.2207, STD: 0.8954\n",
      "Episode: 1037/2000 , Avg Loss: 1484.2053, Eigenval: 4.0000, Neighbor: 15.0000, Mean: 20.3103, STD: 0.8965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m     selected_node \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(predicted_value_next[mask][feasible_actions])\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    113\u001b[0m     index \u001b[38;5;241m=\u001b[39m feasible_actions\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39msqueeze()[selected_node]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 114\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[index]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    115\u001b[0m     actions\u001b[38;5;241m.\u001b[39mappend(index)   \u001b[38;5;66;03m# choose a feasible action\u001b[39;00m\n\u001b[1;32m    117\u001b[0m discounted_rewards \u001b[38;5;241m=\u001b[39m discount_rate\u001b[38;5;241m*\u001b[39mtarget[actions]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as dc\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "verbose = True\n",
    "discount_rate = 1\n",
    "max_episodes = 2000\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "epsilon_decay = 1 / 900\n",
    "epsilon = 1.0\n",
    "batch_size = 32\n",
    "max_grad_norm = 1.0\n",
    "update_target_iters = 100\n",
    "budget = 5\n",
    "\n",
    "# Enviroment\n",
    "env = NodeImmunization(\n",
    "    budget=budget,\n",
    "    device=device,\n",
    "    graph=nx_graph,\n",
    "    )\n",
    "\n",
    "# Replay Buffer\n",
    "buffer = ReplayBuffer(num_nodes, size=5000, batch_size=batch_size, gamma=discount_rate)\n",
    "\n",
    "update_iters = 0\n",
    "eigen_vals = []\n",
    "total_loss = []\n",
    "neighbors = []\n",
    "for episode in range(1, max_episodes+1):\n",
    "        ob = env.register(graph)\n",
    "        done = False\n",
    "        mean_loss = []\n",
    "        while not done:\n",
    "            # Run policy to collect data\n",
    "            q_value.eval()\n",
    "            with torch.no_grad():\n",
    "                mask = (env.x == 0).squeeze()\n",
    "                \n",
    "                node_value = q_value(node_idx, graph.edge_index, ob)\n",
    "                \n",
    "                # choose action\n",
    "                if epsilon > np.random.random():\n",
    "                    randomly_selected_node = random.choice(range(mask.sum().item()))\n",
    "                    index = mask.nonzero().squeeze()[randomly_selected_node]\n",
    "                    action = index\n",
    "                else:\n",
    "                    selected_node = torch.argmax(node_value[mask]).item()\n",
    "                    index = mask.nonzero().squeeze()[selected_node]\n",
    "                    action = index\n",
    "                    \n",
    "                # take action\n",
    "                next_ob, reward, done = env.step(action)\n",
    "                \n",
    "                # store the trajectory\n",
    "                buffer.store(\n",
    "                    ob.squeeze().cpu().numpy(),\n",
    "                    action.item(),\n",
    "                    reward,\n",
    "                    next_ob.squeeze().cpu().numpy(),\n",
    "                    done.item()\n",
    "                )\n",
    "                ob = next_ob\n",
    "            #################################################################\n",
    "\n",
    "\n",
    "\n",
    "            count = 0\n",
    "            avg_loss = 0\n",
    "            for iters in range(1):\n",
    "                # only start to train when we have enough samples\n",
    "                if buffer.size - 8 > buffer.batch_size:\n",
    "\n",
    "                    ########## data preparation ###############################################\n",
    "                    verbose = True\n",
    "                    batch_data = buffer.sample_batch()\n",
    "                    batch_dataset = []\n",
    "\n",
    "                    for i in range(batch_data[\"obs\"].shape[0]):\n",
    "                        G = dc(graph).cpu()\n",
    "                        G.x = node_idx.cpu()\n",
    "                        next_obs = torch.from_numpy(batch_data['next_obs'][i])\n",
    "                        obs = torch.from_numpy(batch_data['obs'][i])\n",
    "                        G.obs = obs\n",
    "                        G.next_obs = next_obs\n",
    "                        G.rews = torch.tensor([batch_data['rews'][i]])\n",
    "                        G.y = torch.zeros(num_nodes, 1).squeeze()\n",
    "                        G.y[int(batch_data['acts'][i])] = 1\n",
    "                        G.done = torch.tensor([batch_data['done'][i]], dtype=torch.bool)\n",
    "                        G.indices = batch_data[\"indices\"][i]\n",
    "                        # G.weights = batch_data[\"weights\"][i]\n",
    "                \n",
    "                        batch_dataset.append(G)\n",
    "                    #########################################################################\n",
    "                    \n",
    "\n",
    "\n",
    "                    ################## Q-learning #############################################\n",
    "                    loader1 = DataLoader(batch_dataset, batch_size=batch_size, shuffle=False)\n",
    "                    for batch in loader1:\n",
    "                        # Target\n",
    "                        batch = batch.to(device)\n",
    "                        with torch.no_grad():\n",
    "                            \n",
    "                            target = target_q_value(batch.x, batch.edge_index, batch.next_obs).detach()\n",
    "                            predicted_value_next = q_value(batch.x, batch.edge_index, batch.next_obs).detach()\n",
    "                            \n",
    "                            actions = []\n",
    "                            for i in range(len(batch.rews)):\n",
    "                                mask = (batch.batch == i).squeeze()\n",
    "                                feasible_actions = (batch.obs[mask] == 0).squeeze()\n",
    "                                selected_node = torch.argmax(predicted_value_next[mask][feasible_actions]).item()\n",
    "                                index = feasible_actions.nonzero().squeeze()[selected_node].item()\n",
    "                                index = mask.nonzero().squeeze()[index].item()\n",
    "                                actions.append(index)   # choose a feasible action\n",
    "\n",
    "                            discounted_rewards = discount_rate*target[actions].squeeze()\n",
    "                            discounted_rewards[batch.done] = 0      # set to 0 if it it the last step\n",
    "                            target = batch.rews + discounted_rewards\n",
    "\n",
    "                        # Train\n",
    "                        q_value.train()\n",
    "                        predicted_value = q_value(batch.x, batch.edge_index, batch.obs) \n",
    "                        elementwise_loss = 0.5*((target - predicted_value[batch.y==1].squeeze())**2)\n",
    "                    \n",
    "                    loss = (elementwise_loss).sum()\n",
    "                    avg_loss += loss.detach().item()\n",
    "                    count += 1\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                            q_value.parameters(), \n",
    "                            max_grad_norm\n",
    "                            )\n",
    "                    optimizer.step()\n",
    "                    ######################################################################################\n",
    "                    started = True\n",
    "                else:\n",
    "                    started = False\n",
    "                    continue\n",
    "            # logging loss\n",
    "            mean_loss.append(avg_loss/(count+1e-8))\n",
    "\n",
    "            # Set two networks equal for every \"update_target_iters\" steps\n",
    "            update_iters += 1\n",
    "            if update_iters % update_target_iters == 0:\n",
    "                target_q_value.load_state_dict(q_value.state_dict())\n",
    "                update_iters = 0\n",
    "                # epsilon = 0.9\n",
    "\n",
    "            # Polyak averaging\n",
    "            # target_q_value.load_state_dict(polyak_avg(target_q_value.state_dict(), q_value.state_dict()))\n",
    "\n",
    "        # Update epsilon\n",
    "        epsilon = max(\n",
    "            min_epsilon, epsilon - (\n",
    "                max_epsilon - min_epsilon\n",
    "            ) * epsilon_decay\n",
    "        )\n",
    "\n",
    "        if started:\n",
    "            # logging the true eigen drop\n",
    "            G = dc(nx_graph)\n",
    "            G.remove_nodes_from(torch.where(ob == 1)[0].cpu().numpy())\n",
    "            adj = nx.adjacency_matrix(G, dtype=float)\n",
    "            eigenval, _ = sparse.linalg.eigsh(adj, k=1, which='LA')\n",
    "            eigen_vals.append(eigenval)\n",
    "            total_loss.append(np.mean(mean_loss))\n",
    "            neighbors.append(compute_total_degree(nx_graph, torch.where(ob == 1)[0].cpu().numpy()))\n",
    "            \n",
    "            if verbose:\n",
    "                # torch.save(q_value.state_dict(), model_path)\n",
    "                # writer.writerow({\n",
    "                #     'episode': episode, \n",
    "                #     'avg loss': np.mean(mean_loss),\n",
    "                #     'eigenval': eigenval.item()})\n",
    "                print(\"Episode: {}/{} , Avg Loss: {:.4f}, Eigenval: {:.4f}, Neighbor: {:.4f}, Mean: {:.4f}, STD: {:.4f}\".format(\n",
    "                episode, max_episodes, \n",
    "                np.mean(mean_loss), \n",
    "                eigenval.item(), \n",
    "                compute_total_degree(nx_graph, torch.where(ob == 1)[0].cpu().numpy()),\n",
    "                predicted_value.detach().mean().item(),\n",
    "                predicted_value.detach().std().item()\n",
    "                )\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def top_k_indices(numbers, k):\n",
    "    # Find the top-k elements\n",
    "    top_k_elements = heapq.nlargest(k, numbers)\n",
    "    \n",
    "    # Find the indices of these elements in the original list\n",
    "    top_k_indices = [i for i, num in enumerate(numbers) if num in top_k_elements]\n",
    "    \n",
    "    # Handle cases where the same number appears multiple times\n",
    "    seen = set()\n",
    "    unique_top_k_indices = []\n",
    "    for idx in top_k_indices:\n",
    "        if numbers[idx] in seen:\n",
    "            continue\n",
    "        unique_top_k_indices.append(idx)\n",
    "        seen.add(numbers[idx])\n",
    "        if len(unique_top_k_indices) == k:\n",
    "            break\n",
    "    \n",
    "    return unique_top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "def compute_eigenval(nx_graph, node_idx):\n",
    "    G = dc(nx_graph)\n",
    "    G.remove_nodes_from(node_idx)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    adj = nx.adjacency_matrix(G, dtype=float)\n",
    "    after_eigenval, _ = sparse.linalg.eigsh(adj, k=1, which='LA')\n",
    "    return after_eigenval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 nodes deleted. Eigenval: [8.94130557]\n",
      "6 nodes deleted. Eigenval: [8.40438329]\n",
      "45 nodes deleted. Eigenval: [7.95843545]\n",
      "3 nodes deleted. Eigenval: [7.74165463]\n",
      "36 nodes deleted. Eigenval: [7.25580141]\n"
     ]
    }
   ],
   "source": [
    "# NS\n",
    "budget = 5\n",
    "ob = torch.zeros(num_nodes).to(device)\n",
    "actions = []\n",
    "for i in range(budget):\n",
    "    best_res = 0\n",
    "    for j in torch.where(ob==0)[0]:\n",
    "        # import pdb; pdb.set_trace()\n",
    "        tmp = SV(nx_graph, ob, j.item())\n",
    "        if best_res < tmp:\n",
    "            best_res = tmp\n",
    "            action = j.item()\n",
    "    ob[action] = 1\n",
    "    actions.append(action)\n",
    "    eigenval = compute_eigenval(nx_graph, actions)\n",
    "    print(f\"{action} nodes deleted. Eigenval: {eigenval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08924121104986305"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = torch.zeros(num_nodes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = load_highschool()\n",
    "num_nodes = 70\n",
    "edge_index = to_undirected(edge_index, num_nodes=num_nodes)\n",
    "node_idx = torch.arange(num_nodes).to(device)\n",
    "graph = Data(x=node_idx.cpu(), edge_index=edge_index)\n",
    "nx_graph = to_networkx(graph)\n",
    "node_degrees = degree(graph.edge_index[0], num_nodes=num_nodes)\n",
    "random_walk_pe = torch.load(\"datasets/random_walk_pe_highschool_64.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_largest_degree = sorted(nx_graph.degree, key=lambda x: x[1], reverse=True)[:5]\n",
    "nodes = [node for node, degree in nodes_with_largest_degree]\n",
    "\n",
    "\n",
    "compute_total_degree(nx_graph, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  5.,  5., 14., 13., 13., 13.,  3.,  9.,  2.,  6.,  9.,  8.,  6.,\n",
       "        10., 11.,  5.,  6., 10.,  6.,  9.,  8.,  5.,  3.,  5.,  6., 13., 19.,\n",
       "         3.,  7.,  8.,  9.,  9., 10.,  7.,  9., 15.,  7.,  9., 13.,  7.,  8.,\n",
       "         8.,  9.,  8., 15.,  2.,  9.,  5.,  8.,  3.,  5.,  7.,  9.,  4., 12.,\n",
       "         6.,  7.,  8.,  2.,  6.,  7., 13.,  7.,  7.,  6.,  9.,  8.,  3.,  5.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 38), (36, 30), (45, 30), (3, 28), (4, 26)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_largest_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "q_value.eval()\n",
    "ob = env.register(graph)\n",
    "done = False\n",
    "mean_loss = []\n",
    "while not done:\n",
    "    # Run policy to collect data\n",
    "    with torch.no_grad():\n",
    "        mask = (env.x == 0).squeeze()\n",
    "        \n",
    "        node_value = q_value(node_idx, graph.edge_index, ob)\n",
    "        \n",
    "        # choose action\n",
    "        if epsilon > np.random.random():\n",
    "            randomly_selected_node = random.choice(range(mask.sum().item()))\n",
    "            index = mask.nonzero().squeeze()[randomly_selected_node]\n",
    "            action = index\n",
    "        else:\n",
    "            selected_node = torch.argmax(node_value[mask]).item()\n",
    "            index = mask.nonzero().squeeze()[selected_node]\n",
    "            action = index\n",
    "            \n",
    "        # take action\n",
    "        next_ob, _, done = env.step(action)\n",
    "        ob = next_ob\n",
    "    \n",
    "compute_total_degree(nx_graph, ob.squeeze().nonzero().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(neighbors, label=\"neighbor\")\n",
    "plt.plot(total_loss, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neighbors, label=\"neighbor\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(buffer.rews_buf, label=\"reward\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_total_degree(nx_graph, torch.where(ob == 1)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
